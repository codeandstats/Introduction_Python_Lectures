[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lectures",
    "section": "",
    "text": "On this html page you will find a collection of the lectures from Digital Literacy I: Coding A SoSe-2023."
  },
  {
    "objectID": "IntroCoding_Lecture0.html",
    "href": "IntroCoding_Lecture0.html",
    "title": "1  Data Types",
    "section": "",
    "text": "Knowing about data types in Python is crucial for several reasons:\nOverall, having knowledge of data types in Python enables you to write robust, efficient, and understandable code that operates correctly with the data it handles. It empowers you to make informed decisions about memory usage, data manipulation, input validation, and code integration, leading to better overall programming proficiency."
  },
  {
    "objectID": "IntroCoding_Lecture0.html#scalar-types",
    "href": "IntroCoding_Lecture0.html#scalar-types",
    "title": "1  Data Types",
    "section": "Scalar Types",
    "text": "Scalar Types\n\nPython has a small set of built-in types for handling numerical data, strings, Boolean (True or False) values, and dates and time. These “single value” types are sometimes called scalar types, and we refer to them in this book as scalars . See Standard Python scalar types for a list of the main scalar types. Date and time handling will be discussed separately, as these are provided by the datetime module in the standard library.\n\n\n\n?(caption)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStandard Python scalar types\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\n\n\n\n\n\n\n\n\n\n\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNone\n\n\n\n\n\n\n\n\n\n\n\n\nThe Python “null” value (only one instance of the None object exists)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstr\n\n\n\n\n\n\n\n\n\n\n\n\nString type; holds Unicode strings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbytes\n\n\n\n\n\n\n\n\n\n\n\n\nRaw binary data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfloat\n\n\n\n\n\n\n\n\n\n\n\n\nDouble-precision floating-point number (note there is no separate double type)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbool\n\n\n\n\n\n\n\n\n\n\n\n\nA Boolean True or False value\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nint\n\n\n\n\n\n\n\n\n\n\n\n\nArbitrary precision integer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx = 5\ntype(x)\n\nint\n\n\n\ny=7.5\ntype(y)\n\nfloat\n\n\n\ntype(x+y)\n\nfloat\n\n\n\nNumeric Type\n\nThe primary Python types for numbers are int and float. An int can store arbitrarily large numbers:\n\n\nival = 17239871\nival ** 6\n\n26254519291092456596965462913230729701102721\n\n\n\n\nBooleans\ncan take only two values: True and False.\n\nprint(4 == 5)\nprint(4 < 5)\nb = 4 != 5\nprint(b)\nprint(int(b))\n\nFalse\nTrue\nTrue\n1"
  },
  {
    "objectID": "IntroCoding_Lecture0.html#strings",
    "href": "IntroCoding_Lecture0.html#strings",
    "title": "1  Data Types",
    "section": "Strings",
    "text": "Strings\n\nMany people use Python for its built-in string handling capabilities. You can write string literals using either single quotes ’ or double quotes “ (double quotes are generally favored):\n\n\na = 'one way of writing a string'\nb = \"another way\"\n\ntype(a)\n\nstr\n\n\nFor multiline strings with line breaks, you can use triple quotes, either ''' or \"\"\":\n\nc = \"\"\"\nThis is a longer string that\nspans multiple lines\n\"\"\"\n\n\nc.count(\"\\n\")\n\n3\n\n\n\nStrings built-in methods\n\nNote: All string methods return new values. They do not change the original string.\n\n\n\n\n\nMethod\n\n\nDescription\n\n\n\n\ncapitalize()\n\n\nConverts the first character to upper case\n\n\n\n\ncasefold()\n\n\nConverts string into lower case\n\n\n\n\ncenter()\n\n\nReturns a centered string\n\n\n\n\ncount()\n\n\nReturns the number of times a specified value occurs in a string\n\n\n\n\nencode()\n\n\nReturns an encoded version of the string\n\n\n\n\nendswith()\n\n\nReturns true if the string ends with the specified value\n\n\n\n\nexpandtabs()\n\n\nSets the tab size of the string\n\n\n\n\nfind()\n\n\nSearches the string for a specified value and returns the position of where it was found\n\n\n\n\nformat()\n\n\nFormats specified values in a string\n\n\n\n\nformat_map()\n\n\nFormats specified values in a string\n\n\n\n\nindex()\n\n\nSearches the string for a specified value and returns the position of where it was found\n\n\n\n\nisalnum()\n\n\nReturns True if all characters in the string are alphanumeric\n\n\n\n\nisalpha()\n\n\nReturns True if all characters in the string are in the alphabet\n\n\n\n\nisascii()\n\n\nReturns True if all characters in the string are ascii characters\n\n\n\n\nisdecimal()\n\n\nReturns True if all characters in the string are decimals\n\n\n\n\nisdigit()\n\n\nReturns True if all characters in the string are digits\n\n\n\n\nisidentifier()\n\n\nReturns True if the string is an identifier\n\n\n\n\nislower()\n\n\nReturns True if all characters in the string are lower case\n\n\n\n\nisnumeric()\n\n\nReturns True if all characters in the string are numeric\n\n\n\n\nisprintable()\n\n\nReturns True if all characters in the string are printable\n\n\n\n\nisspace()\n\n\nReturns True if all characters in the string are whitespaces\n\n\n\n\nistitle()\n\n\nReturns True if the string follows the rules of a title\n\n\n\n\nisupper()\n\n\nReturns True if all characters in the string are upper case\n\n\n\n\njoin()\n\n\nConverts the elements of an iterable into a string\n\n\n\n\nljust()\n\n\nReturns a left justified version of the string\n\n\n\n\nlower()\n\n\nConverts a string into lower case\n\n\n\n\nlstrip()\n\n\nReturns a left trim version of the string\n\n\n\n\nmaketrans()\n\n\nReturns a translation table to be used in translations\n\n\n\n\npartition()\n\n\nReturns a tuple where the string is parted into three parts\n\n\n\n\nreplace()\n\n\nReturns a string where a specified value is replaced with a specified value\n\n\n\n\nrfind()\n\n\nSearches the string for a specified value and returns the last position of where it was found\n\n\n\n\nrindex()\n\n\nSearches the string for a specified value and returns the last position of where it was found\n\n\n\n\nrjust()\n\n\nReturns a right justified version of the string\n\n\n\n\nrpartition()\n\n\nReturns a tuple where the string is parted into three parts\n\n\n\n\nrsplit()\n\n\nSplits the string at the specified separator, and returns a list\n\n\n\n\nrstrip()\n\n\nReturns a right trim version of the string\n\n\n\n\nsplit()\n\n\nSplits the string at the specified separator, and returns a list\n\n\n\n\nsplitlines()\n\n\nSplits the string at line breaks and returns a list\n\n\n\n\nstartswith()\n\n\nReturns true if the string starts with the specified value\n\n\n\n\nstrip()\n\n\nReturns a trimmed version of the string\n\n\n\n\nswapcase()\n\n\nSwaps cases, lower case becomes upper case and vice versa\n\n\n\n\ntitle()\n\n\nConverts the first character of each word to upper case\n\n\n\n\ntranslate()\n\n\nReturns a translated string\n\n\n\n\nupper()\n\n\nConverts a string into upper case\n\n\n\n\nzfill()\n\n\nFills the string with a specified number of 0 values at the beginning\n\n\n\n\n\n\nMethods\nMany operations/functions in python are specific to the data type even though we use the same syntax:\n\nprint(x+y)\nprint(a+b)\n\n12.5\none way of writing a stringanother way\n\n\n\nType conversion\nWe can often convert from one type to another if it makes sense:\n\nstr(x)\n\n'5'\n\n\n\nfloat(x)\n\n5.0"
  },
  {
    "objectID": "IntroCoding_Lecture0.html#immutable-objects",
    "href": "IntroCoding_Lecture0.html#immutable-objects",
    "title": "1  Data Types",
    "section": "Immutable Objects",
    "text": "Immutable Objects\nMutable objects are those that allow you to change their value or data in place without affecting the object’s identity. In contrast, immutable objects don’t allow this kind of operation. You’ll just have the option of creating new objects of the same type with different values.\nIn Python, mutability is a characteristic that may profoundly influence your decision when choosing which data type to use in solving a given programming problem. Therefore, you need to know how mutable and immutable objects work in Python.\nIn Python, variables don’t have an associated type or size, as they’re labels attached to objects in memory. They point to the memory position where concrete objects live. In other words, a Python variable is a name that refers to or holds a reference to a concrete object. In contrast, Python objects are concrete pieces of information that live in specific memory positions on your computer.\nThe main takeaway here is that variables and objects are two different animals in Python:\n\nVariables hold references to objects.\nObjects live in concrete memory positions.\n\nRead more about this topic\nStrings and tuples are immutable:\n\na = \"this is a string\"\n\na[10] = \"f\"\n\nTypeError: 'str' object does not support item assignment"
  },
  {
    "objectID": "IntroCoding_Lecture0.html#tuples",
    "href": "IntroCoding_Lecture0.html#tuples",
    "title": "1  Data Types",
    "section": "Tuples",
    "text": "Tuples\n\nA tuple is a fixed-length, immutable sequence of Python objects which, once assigned, cannot be changed. The easiest way to create one is with a comma-separated sequence of values wrapped in parentheses:\n\n\ntup = (4, 5, 6)\nprint(tup)\ntup = (4, \"Ray\", 6)\nprint(tup)\n#In many contexts, the parentheses can be omitted\ntup = 4, \"Ray\", 6\nprint(tup)\n\n(4, 5, 6)\n(4, 'Ray', 6)\n(4, 'Ray', 6)\n\n\nElements can be accessed with square brackets [] as with most other sequence types. As in C, C++, Java, and many other languages, sequences are 0-indexed in Python:\n\ntup[0]\n\n4\n\n\n\n#but you cannot change the value:\ntup[0] = 3\n\nTypeError: 'tuple' object does not support item assignment\n\n\nYou can concatenate tuples using the + operator to produce longer tuples:\n\n(4, None, 'foo') + (6, 0) + ('bar',)\n\n(4, None, 'foo', 6, 0, 'bar')\n\n\nMultiplying a tuple by an integer, as with lists, has the effect of concatenating that many copies of the tuple:\n\n('foo', 'bar') * 4\n\n('foo', 'bar', 'foo', 'bar', 'foo', 'bar', 'foo', 'bar')\n\n\n\nUnpacking tuples\nIf you try to assign to a tuple-like expression of variables, Python will attempt to unpack the value on the righthand side of the equals sign:\n\ntup = (4, 5, 6)\na, b, c = tup"
  },
  {
    "objectID": "IntroCoding_Lecture1.html",
    "href": "IntroCoding_Lecture1.html",
    "title": "2  Lists and Loops",
    "section": "",
    "text": "Lists\n\nDataCamp, Introduction to Python, Chap 2\n\nLoops\n\nDataCamp, Intermediate Python, Chap 4\n\nConditions\n\nDataCamp, Intermediate Python, Chap 3\n\n\n\nList\nIn contrast with tuples, lists are variable length and their contents can be modified in place. Lists are mutable. You can define them using square brackets [] or using the list type function:\n\nfam = [1.73, 1.68, 1.71, 1.89]\nfam = list((1.73, 1.68, 1.71, 1.89))\nfam\n\n[1.73, 1.68, 1.71, 1.89]\n\n\nYou can sort, append,insert, concatenate, …\n\n#sorting is in place!\nfam.sort()\nfam\n\n\nfam.append(2.05)\nfam\n\n\nfam + fam\n\n[1.73, 1.68, 1.71, 1.89, 1.73, 1.68, 1.71, 1.89]\n\n\nLists can\n\nContain any type\nContain different types\n\n\nfam2 = [\"liz\", 1.73, \"emma\", 1.68, \"mom\", 1.71, \"dad\", 1.89]\nfam2\n\n['liz', 1.73, 'emma', 1.68, 'mom', 1.71, 'dad', 1.89]\n\n\n\n\nList of lists\n\nfam3 = [[\"liz\", 1.73],\n         [\"emma\", 1.68],\n         [\"mom\", 1.71],\n         [\"dad\", 1.89]]\nfam3\n\n[['liz', 1.73], ['emma', 1.68], ['mom', 1.71], ['dad', 1.89]]\n\n\n\n\nSlicing\n\nYou can select sections of most sequence types by using slice notation, which in its basic form consists of start:stop passed to the indexing operator []:\n\n\nfam[1:3]\n\n[1.68, 1.71]\n\n\n\nWhile the element at the start index is included, the stop index is not included, so that the number of elements in the result is stop - start.\n\n\nEither the start or stop can be omitted, in which case they default to the start of the sequence and the end of the sequence, respectively:\n\n\nprint(fam[1:])\nprint(fam[:3])\n\n[1.68, 1.71, 1.89]\n[1.73, 1.68, 1.71]\n\n\nNegative indices slice the sequence relative to the end:\n\nfam[-4:]\n\n[1.73, 1.68, 1.71, 1.89]\n\n\n\nSlicing semantics takes a bit of getting used to, especially if you’re coming from R or MATLAB. See this helpful illustration of slicing with positive and negative integers. In the figure, the indices are shown at the “bin edges” to help show where the slice selections start and stop using positive or negative indices.\n\n\n\n\nIllustration of Python slicing conventions\n\n\n\n\n\nManipulating lists of lists\nThe following list of lists contains names of sections in a house and their area.\n\nExtract the area corresponding to kitchen\nString Tasks:\n\nExtract the first letters of each string\nCapitalize all strings\nReplace all occurrences of “room” with “rm”\ncount the number of “l” in “hallway”\n\nInsert a “home office” with area 10.75 after living room\nAppend the total area to the end of the list\nBoolean operations:\n\nGenerate one True and one False by comparing areas\nGenerate one True and one False by comparing names\n\n\n\nhouse = [['hallway', 11.25],\n ['kitchen', 18.0],\n ['living room', 20.0],\n ['bedroom', 10.75],\n ['bathroom', 9.5]]\n\n\n\nAutomation by iterating\nfor loops are a powerful way of automating MANY otherwise tedious tasks that repeat.\nThe syntax template is (watch the indentation!):\nfor var in seq :\n     expression\n\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\n#We can use lists:\nfor f in fam:\n    print(f)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.73\n1.68\n1.71\n1.89\n```\n:::\n:::\n\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\n#or iterators\nfor i in range(len(fam)):\n    print(fam[i])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.73\n1.68\n1.71\n1.89\n```\n:::\n:::\n\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\n#or enumerate\nfor i,f in enumerate(fam):\n    print(fam[i], f)\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n1.73 1.73\n1.68 1.68\n1.71 1.71\n1.89 1.89\n```\n:::\n:::\n\n\n### Iterators (Optional)\n\nAn iterator is an object that contains a countable number of values.\n\nAn iterator is an object that can be iterated upon, meaning that you can traverse through all the values.\n\nTechnically, in Python, an iterator is an object which implements the iterator protocol, which consist of the methods `iter()` and `next()`.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\nmytuple = (\"apple\", \"banana\", \"cherry\")\nmyit = iter(mytuple)\n\nprint(next(myit))\nprint(next(myit))\n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\napple\nbanana\n```\n:::\n:::\n\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\nmystr = \"banana\"\nmyit = iter(mystr)\n\nprint(next(myit))\nprint(next(myit))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nb\na\n```\n:::\n:::\n\n\nStrings are also iterable objects, containing a sequence of characters:\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n#funny iterators\nprint(range(5))\nlist(range(5))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nrange(0, 5)\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n[0, 1, 2, 3, 4]\n```\n:::\n:::\n\n\n1. Repeat the tasks 2 and 4 from above by using a for loop\n    - using `enumerate`\n    - using `range`\n2. Create two separates new lists which contain only the names and areas separately\n3. [Clever Carl](https://nrich.maths.org/2478#:~:text=Gauss%20added%20the%20rows%20pairwise,quantity%20in%20a%20clever%20way.): Compute \n$$\n\\sum_{i=1}^{100}{i}\n$$ \n\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\n\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\n[0, 1, 2, 3, 4]\n```\n:::\n:::\n\n\n### Conditions\n\nThe syntax template is (watch the indentation!):\n\nif condition: expression\n\nfor f in fam:\n    if f > 1.8:\n        print(f)\n\n1.89\n\n\n\nFind the max of the areas by using if inside a for loop\nPrint those elements of the list with\n\narea \\(> 15\\)\nstrings that contain “room” (or “rm” after your substitution)"
  },
  {
    "objectID": "IntroCoding_Lecture2.html",
    "href": "IntroCoding_Lecture2.html",
    "title": "3  Dictionaries and Functions",
    "section": "",
    "text": "Functions\n\nDataCamp, Introduction to Python, Chap 3\n\nDictionaries\n\nDataCamp, Intermediate Python, Chap 2\n\nIntroduction to numpy\n\nDataCamp, Introduction to Python, Chap 4\n\n\n\nFunctions\nFunctions are essential building blocks to reuse code and to modularize code.\nWe have already seen and used many built-in functions/methods such as print(), len(), max(), round(), index(), capitalize(), etc..\n\nareas = [11.25, 18.0, 20.0, 10.75, 10.75, 9.5]\nprint(max(areas))\nprint(len(areas))\nprint(round(10.75,1))\nprint(areas.index(18.0))\n\n20.0\n6\n10.8\n1\n\n\nBut of course we want to define our own functions as well ! As a rule of thumb, if you anticipate needing to repeat the same or very similar code more than once, it may be worth writing a reusable function. Functions can also help make your code more readable by giving a name to a group of Python statements.\nFor example, we computed the BMI previously as follows:\n\nheight = 1.79\nweight = 68.7\nbmi = weight/height**2\nprint(bmi)\n\n21.44127836209856\n\n\nFunctions are declared with the def keyword. A function contains a block of code with an optional use of the return keyword:\n\ndef compute_bmi(height, weight):\n    return weight/height**2\n\ncompute_bmi(1.79, 68.7)\n\n21.44127836209856\n\n\nEach function can have positional arguments and keyword arguments. Keyword arguments are most commonly used to specify default values or optional arguments. For example:\n\ndef compute_bmi(height, weight, ndigits=2):\n    return round(weight/height**2, ndigits)\n\nprint(compute_bmi(1.79, 68.7))\nprint(compute_bmi(1.79, 68.7,4))\n\n21.44\n21.4413\n\n\n\nMultiple Return Values\nare easily possible in python:\n\ndef compute_bmi(height, weight, ndigits=2):\n    bmi = round(weight/height**2, ndigits)\n    #https://www.cdc.gov/healthyweight/assessing/index.html#:~:text=If%20your%20BMI%20is%20less,falls%20within%20the%20obese%20range.\n    if bmi < 18.5:\n        status=\"underweight\"\n    elif bmi <= 24.9:\n        status=\"healthy\"\n    elif bmi <= 29.9:\n        status=\"underweight\"\n    elif bmi >= 30:#note that a simple else would suffice here!\n        status=\"obese\"\n    return bmi, status\n\nprint(compute_bmi(1.79, 68.7))\nprint(compute_bmi(1.79, 55))\n\n(21.44, 'healthy')\n(17.17, 'underweight')\n\n\nRecall from the previous lab how we\n\nfound the largest room,\ncomputed the sum of integers from 1 to 100\n\n\n#find the maximum area:\nareas = [11.25, 18.0, 20.0, 10.75, 10.75, 9.5]\ncurrentMax = areas[0] # initialize to the first area seen\n\nfor a in areas:\n  if a > currentMax:\n    currentMax = a\n\nprint(\"The max is:\", currentMax)\n\nThe max is: 20.0\n\n\n\n#Clever IDB students: Compute the sum from 1 to 100:\nTotal =0\n\nfor i in range(101):#strictly speaking we are adding the first  0 \n  Total = Total + i\n  #Total += i\n\nprint(Total)\n\n\n\nTasks\nWrite your own function\n\nto find the min and max of a list\nto compute the Gauss sum with defaukt values \\(m=1, n=100\\)\n\n\\[\n\\sum_{i=m}^{n}{i}\n\\]\n\n\nNamespaces and Scope\nFunctions seem straightforward. But one of the more confusing aspects in the beginning is the concept that we can have multiple instances of the same variable!\nFunctions can access variables created inside the function as well as those outside the function in higher (or even global) scopes. An alternative and more descriptive name describing a variable scope in Python is a namespace. Any variables that are assigned within a function by default are assigned to the local namespace. The local namespace is created when the function is called and is immediately populated by the function’s arguments. After the function is finished, the local namespace is destroyed.\nExamples:\n\nheight = 1.79\nweight = 68.7\nbmi = weight/height**2\n#print(\"height, weight, bmi OUTSIDE the function:\",height, weight,bmi)\n\ndef compute_bmi(h, w):\n    height = h\n    weight = w\n    bmi = round(weight/height**2,2)\n    status=\"healthy\"\n    print(\"height, weight, bmi INSIDE the function:\",height, weight,bmi)\n    print(\"status:\", status)\n    return bmi\n\ncompute_bmi(1.55, 50)\n\nprint(\"height, weight, bmi OUTSIDE the function:\",height, weight,bmi)\n#print(status)\n\nheight, weight, bmi INSIDE the function: 1.55 50 20.81\nstatus: healthy\nheight, weight, bmi OUTSIDE the function: 1.79 68.7 21.44127836209856\n\n\n\n\n\nDictionaries\nA dictionary is basically a lookup table. It stores a collection of key-value pairs, where key and value are Python objects. Each key is associated with a value so that a value can be conveniently retrieved, inserted, modified, or deleted given a particular key.\nThe dictionary or dict may be the most important built-in Python data structure. In other programming languages, dictionaries are sometimes called hash maps or associative arrays.\n\n#This was the house defined as a list of lists:\nhouse = [['hallway', 11.25],\n ['kitchen', 18.0],\n ['living room', 20.0],\n ['bedroom', 10.75],\n ['bathroom', 9.5]]\n\n#Remember all the disadvantages of accessing elements\n\n#Better as a lookup table:\nhouse = {'hallway': 11.25,\n    'kitchen': 18.0,\n    'living room': 20.0,\n    'bedroom': 10.75,\n    'bathroom': 9.5}\n\n\neurope = {'spain':'madrid', 'france' : 'paris'}\nprint(europe[\"spain\"])\nprint(\"france\" in europe)\nprint(\"paris\" in europe)#only checks the keys!\neurope[\"germany\"] = \"berlin\"\nprint(europe.keys())\nprint(europe.values())\n\nmadrid\nTrue\nFalse\ndict_keys(['spain', 'france', 'germany'])\ndict_values(['madrid', 'paris', 'berlin'])\n\n\n\n\nDictionaries from lists\nHow would we convert two lists into a key: value pair dictionary?\nMethod 1: using zip\n\nrooms=['hallway', 'kitchen', 'living room', 'bedroom', 'bathroom']\nareas=[11.25, 18.0, 20.0, 10.75, 9.5]\n#create list of tuples\nlist(zip(rooms, areas))\n\n[('hallway', 11.25),\n ('kitchen', 18.0),\n ('living room', 20.0),\n ('bedroom', 10.75),\n ('bathroom', 9.5)]\n\n\n\ndict(zip(rooms, areas))\n\n{'hallway': 11.25,\n 'kitchen': 18.0,\n 'living room': 20.0,\n 'bedroom': 10.75,\n 'bathroom': 9.5}\n\n\nIf you need to iterate over both the keys and values, you can use the items method to iterate over the keys and values as 2-tuples:\n\n#print(list(europe.items()))\n\nfor country, capital in europe.items():\n    print(capital, \"is the capital of\", country)\n\nmadrid is the capital of spain\nparis is the capital of france\nberlin is the capital of germany\n\n\nNote: You can use integers as keys as well. However -unlike in lists- one should not think of them as positional indices!\n\n#Assume you have a basement:\nhouse[0] = 21.5\nhouse\n\n{'hallway': 11.25,\n 'kitchen': 18.0,\n 'living room': 20.0,\n 'bedroom': 10.75,\n 'bathroom': 9.5,\n 0: 21.5}\n\n\n\n#And there is a difference between the string and the integer index!\nhouse[\"0\"] = 30.5\nhouse\n\n{'hallway': 11.25,\n 'kitchen': 18.0,\n 'living room': 20.0,\n 'bedroom': 10.75,\n 'bathroom': 9.5,\n 0: 21.5}\n\n\nCategorize a list of words by their first letters as a dictionary of lists:\n\nwords = [\"apple\", \"bat\", \"bar\", \"atom\", \"book\"]\n\nby_letter = {}\n\nfor word in words:\n     letter = word[0]\n     if letter not in by_letter:\n        by_letter[letter] = [word]\n     else:\n         by_letter[letter].append(word)\n\n{'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}\n\n\n\nTasks\n\nFind the maximum of the areas of the houses\nRemove the two last entries.\nWrite a function named word_count that takes a string as input and returns a dictionary with each word in the string as a key and the number of times it appears as the value.\n\n\n\n\nIntroduction to numpy\nNumPy, short for Numerical Python, is one of the most important foundational packages for numerical computing in Python.\n\nVectorized, fast mathematical operations.\nKey features of NumPy is its N-dimensional array object, or ndarray\n\n\nheight = [1.79, 1.85, 1.95, 1.55]\nweight = [70, 80, 85, 65]\n\n#bmi = weight/height**2\n\n\nimport numpy as np\n\nheight = np.array([1.79, 1.85, 1.95, 1.55])\nweight = np.array([70, 80, 85, 65])\n\nbmi = weight/height**2\nnp.round(bmi,2)\n\narray([21.84700852, 23.37472608, 22.35371466, 27.05515088])"
  },
  {
    "objectID": "IntroCoding_Lecture3.html",
    "href": "IntroCoding_Lecture3.html",
    "title": "4  Intro to numpy",
    "section": "",
    "text": "In this lecture we will get to know and become experts in:"
  },
  {
    "objectID": "IntroCoding_Lecture3.html#introduction-to-numpy",
    "href": "IntroCoding_Lecture3.html#introduction-to-numpy",
    "title": "4  Intro to numpy",
    "section": "Introduction to numpy",
    "text": "Introduction to numpy\nNumPy, short for Numerical Python, is one of the most important foundational packages for numerical computing in Python.\n\nVectorized, fast mathematical operations.\nKey features of NumPy is its N-dimensional array object, or ndarray\n\n\nheight = [1.79, 1.85, 1.95, 1.55]\nweight = [70, 80, 85, 65]\n\n#bmi = weight/height**2\n\n\nheight = np.array([1.79, 1.85, 1.95, 1.55])\nweight = np.array([70, 80, 85, 65])\n\nbmi = weight/height**2\nbmi\n\narray([21.84700852, 23.37472608, 22.35371466, 27.05515088])\n\n\n\nMultiple Dimensions\nare handled naturally by numpy, e.g.\n\nhw1 = np.array([height, weight])\nprint(hw1)\nprint(hw1.shape)\nhw2 = hw1.transpose()\nprint(hw2)\nprint(hw2.shape)\n\n[[ 1.79  1.85  1.95  1.55]\n [70.   80.   85.   65.  ]]\n(2, 4)\n[[ 1.79 70.  ]\n [ 1.85 80.  ]\n [ 1.95 85.  ]\n [ 1.55 65.  ]]\n(4, 2)\n\n\n\n\nAccessing array elements\nis similar to lists but allows for multidimensional index:\n\nprint(hw2[0,1])\n\n70.0\n\n\n\nprint(hw2[:,0])\n\n[1.79 1.85 1.95 1.55]\n\n\n\nprint(hw2[0])\n#equivalent to\nprint(hw2[0,:])\n#shape:\nprint(hw2[0].shape)\n\n[ 1.79 70.  ]\n[ 1.79 70.  ]\n(2,)\n\n\nTo select a subset of the rows in a particular order, you can simply pass a list or ndarray of integers specifying the desired order:\n\nprint(hw2[[2,0,1]])\n\n[[ 1.95 85.  ]\n [ 1.79 70.  ]\n [ 1.85 80.  ]]\n\n\nNegative indices\n\nprint(hw2)\nprint(\"Using negative indices selects rows from the end:\")\nprint(hw2[[-2,-1]])\n\n[[ 1.79 70.  ]\n [ 1.85 80.  ]\n [ 1.95 85.  ]\n [ 1.55 65.  ]]\nUsing negative indices selects rows from the end:\n[[ 1.95 85.  ]\n [ 1.55 65.  ]]\n\n\nYou can pass multiple slices just like you can pass multiple indexes:\n\nhw2[:2,:1]\n\narray([[1.79],\n       [1.85]])\n\n\n\nReshaping\n\nnp.arange(32).reshape((8, 4))\n\narray([[ 0,  1,  2,  3],\n       [ 4,  5,  6,  7],\n       [ 8,  9, 10, 11],\n       [12, 13, 14, 15],\n       [16, 17, 18, 19],\n       [20, 21, 22, 23],\n       [24, 25, 26, 27],\n       [28, 29, 30, 31]])\n\n\n\n\nBoolean indexing\n\nheight_gt_185 = hw2[:,0]>1.85\nprint(height_gt_185)\nprint(hw2[height_gt_185,1])\n\n[False False  True False]\n[85.]\n\n\nnumpy arrays cannot contain elements with different types. If you try to build such a list, some of the elements’ types are changed to end up with a homogeneous list. This is known as type coercion.\n\nprint(np.array([True, 1, 2]))\nprint(np.array([\"True\", 1, 2]))\nprint(np.array([1.3, 1, 2]))\n\n[1 1 2]\n['True' '1' '2']\n[1.3 1.  2. ]\n\n\nLots of extra useful functions!\n\nnp.zeros((2,3))\n#np.ones((2,3))\n\narray([[0., 0., 0.],\n       [0., 0., 0.]])\n\n\n\nnp.eye(3)\n\narray([[1., 0., 0.],\n       [0., 1., 0.],\n       [0., 0., 1.]])\n\n\n\nnp.column_stack([height, weight])\n\narray([[ 1.79, 70.  ],\n       [ 1.85, 80.  ],\n       [ 1.95, 85.  ],\n       [ 1.55, 65.  ]])"
  },
  {
    "objectID": "IntroCoding_Lecture3.html#data-summaries-in-numpy",
    "href": "IntroCoding_Lecture3.html#data-summaries-in-numpy",
    "title": "4  Intro to numpy",
    "section": "Data Summaries in numpy",
    "text": "Data Summaries in numpy\nWe can compute simple statistics:\n\nprint(np.mean(hw2))\nprint(np.mean(hw2, axis=0))\n\n38.3925\n[ 1.785 75.   ]\n\n\n\nprint(np.unique([1,1,2,1,2,3,2,2,3]))\n\nprint(np.unique([1,1,2,1,2,3,2,2,3], return_counts=True))\n\n[1 2 3]\n(array([1, 2, 3]), array([3, 4, 2], dtype=int64))"
  },
  {
    "objectID": "IntroCoding_Lecture3.html#introduction-to-simulating-probabilistic-events",
    "href": "IntroCoding_Lecture3.html#introduction-to-simulating-probabilistic-events",
    "title": "4  Intro to numpy",
    "section": "Introduction to Simulating Probabilistic Events",
    "text": "Introduction to Simulating Probabilistic Events\n\nGenerating Data in numpy\nMeet your friends:\n\nnp.random.permutation: Return a random permutation of a sequence, or return a permuted range\nnp.random.integers: Draw random integers from a given low-to-high range\nnp.random.choice: Generates a random sample from a given 1-D array\n\n\n# Do this (new version)\nfrom numpy.random import default_rng\nrng = default_rng()\n\nx= np.arange(10)\nprint(x)\nprint(rng.permutation(x))\nprint(rng.permutation(list('intelligence')))\n\n[0 1 2 3 4 5 6 7 8 9]\n[6 7 9 4 1 0 3 8 2 5]\n['t' 'c' 'n' 'l' 'e' 'n' 'i' 'e' 'e' 'l' 'i' 'g']\n\n\n\nprint(rng.integers(0,10,5))\nprint(rng.integers(0,10,(5,2)))\n\n[7 9 7 9 4]\n[[9 0]\n [8 6]\n [6 7]\n [0 5]\n [1 5]]\n\n\n\nrng.choice(x,4)\n\narray([8, 5, 1, 4])\n\n\n\n\nExamples:\n\nSpotify playlist\nMovie List\n\n\nmovies_list = ['The Godfather', 'The Wizard of Oz', 'Citizen Kane', 'The Shawshank Redemption', 'Pulp Fiction']\n\n# pick a random choice from a list of strings.\nmovie = rng.choice(movies_list,2)\nprint(movie)\n\n['The Shawshank Redemption' 'The Godfather']"
  },
  {
    "objectID": "IntroCoding_Lecture3.html#birthday-paradox",
    "href": "IntroCoding_Lecture3.html#birthday-paradox",
    "title": "4  Intro to numpy",
    "section": "Birthday “Paradox”",
    "text": "Birthday “Paradox”\nPlease enter your birthday on google drive https://forms.gle/CeqyRZ4QzWRmJFvs9\nHow many people do you think will share a birthday? Would that be a rare, highly unusual event?\nHow can we find out how likely it is that across \\(n\\) folks in a room at least two share a birthday?\nHint: can we put our random number generators to task ?\n\n# Can you simulate 25 birthdays?\nfrom numpy.random import default_rng \nrng = default_rng()\n\n\n#initialize it to be the empty list:\nshardBday = []\n\nn = 40\n\nPossibleBDays = np.arange(1,366)\n#now \"draw\" 25 random bDays:\nfor i in range(1000):# is the 1000 an important number ??\n#no it only determines the precision of my estimate !!\n  ran25Bdays = rng.choice(PossibleBDays, n, replace = True)\n  #it is of utmost importance to allow for same birthdays !! \n  #rng.choice(PossibleBDays, 366, replace = False)\n  x , cts = np.unique(ran25Bdays ,return_counts=True)\n  shardBday = np.append(shardBday, np.sum(cts>1))#keep this !!\n  #shardBday = np.sum(cts>1)\n\n\n#np.sum(shardBday>0)/1000\nnp.mean(shardBday > 0)\n\n#shardBday = 2\n\n0.893\n\n\n\n5 != 3 #not equal\n\nTrue\n\n\n\n#Boolean indexing !!\nx[cts > 1]\n\narray([ 71, 192])\n\n\n\nx[23]\n\n182\n\n\n\n#can you design a coin flip with an arbitary probability p = 0.25\n#simulate 365 days with a 1/4 chance of being sunny\n\n#fair coin\ncoins = np.random.randint(0,2,365)\n\nnp.unique(coins, return_counts=True)\n\n(array([0, 1]), array([189, 176], dtype=int64))\n\n\n\n\nTossing dice and coins\nLet us toss many dice or coins to find out: - the average value of a six-faced die - the variation around the mean when averaging - the probability of various “common hands” in the game Liar’s Dice: * Full house: e.g., 66111 * Three of a kind: e.g., 44432 * Two pair: e.g., 22551 * Pair: e.g., 66532\nSome real world problems:\n\nOverbooking flights: airlines\nHome Office days: planning office capacities and minimizing social isolation"
  },
  {
    "objectID": "IntroCoding_Lecture4.html",
    "href": "IntroCoding_Lecture4.html",
    "title": "5  Intro to pandas",
    "section": "",
    "text": "In this Introduction to pandas we will get to know and become experts in:\nRelevant DataCamp lessons:"
  },
  {
    "objectID": "IntroCoding_Lecture4.html#introduction-to-pandas",
    "href": "IntroCoding_Lecture4.html#introduction-to-pandas",
    "title": "5  Intro to pandas",
    "section": "Introduction to pandas",
    "text": "Introduction to pandas\nWhile numpy offers a lot of powerful numerical capabilities it lacks some of the necessary convenience and natural of handling data as we encounter them. For example, we would typically like to - mix data types (strings, numbers, categories, Boolean, …) - refer to columns and rows by names - summarize and visualize data in efficient pivot style manners\nAll of the above (and more) can be achieved easily by extending the concept of an array (or a matrix) to a so called dataframe.\nThere are many ways to construct a DataFrame, though one of the most common is from a dictionary of equal-length lists or NumPy arrays:\n\ndata = {\"state\": [\"Ohio\", \"Ohio\", \"Ohio\", \"Nevada\", \"Nevada\", \"Nevada\"],\n        \"year\": [2000, 2001, 2002, 2001, 2002, 2003],\n        \"pop\": [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\nframe = pd.DataFrame(data)# creates a dataframe out of the data given!\nframe.head(3)\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      state\n      year\n      pop\n    \n  \n  \n    \n      0\n      Ohio\n      2000\n      1.5\n    \n    \n      1\n      Ohio\n      2001\n      1.7\n    \n    \n      2\n      Ohio\n      2002\n      3.6\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nframe[2,1]#too bad\n\n\n#to get the full row: use the .iloc method\nframe.iloc[2]\nframe.iloc[2,1]\n\n2002\n\n\n\nSubsetting/Slicing\nWe first need to understand the attributes index (=rownames) and columns (= column names):\n\nframe.index\n\nRangeIndex(start=0, stop=6, step=1)\n\n\n\n#We can set a column as an index:\nframe2 = frame.set_index(\"year\")\nprint(frame2)\n# \n\n       state  pop\nyear             \n2000    Ohio  1.5\n2001    Ohio  1.7\n2002    Ohio  3.6\n2001  Nevada  2.4\n2002  Nevada  2.9\n2003  Nevada  3.2\n\n\n\n#it would be nice to access elements in the same fashion as numpy\n#frame2[1,1]\nframe[\"pop\"]\n\n0    1.5\n1    1.7\n2    3.6\n3    2.4\n4    2.9\n5    3.2\nName: pop, dtype: float64\n\n\n\nframe.pop\n\n<bound method DataFrame.pop of     state  year  pop\n0    Ohio  2000  1.5\n1    Ohio  2001  1.7\n2    Ohio  2002  3.6\n3  Nevada  2001  2.4\n4  Nevada  2002  2.9\n5  Nevada  2003  3.2>\n\n\n\n\nAsking for rows\nUnfortunately, we cannot use the simple [row,col] notation that we are used to from numpy arrays. (Try asking for frame[0,1])\nInstead, row subsetting can be achieved with either the .loc() or the .iloc() methods. The latter takes integers, the former indices:\n\nframe2.loc[2001] #note that I am not using quotes !!\n#at first glance this looks like I am asking for the row number 2001 !!\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      state\n      pop\n    \n    \n      year\n      \n      \n    \n  \n  \n    \n      2001\n      Ohio\n      1.7\n    \n    \n      2001\n      Nevada\n      2.4\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nframe2.loc[2001,\"state\"]\n\nyear\n2001      Ohio\n2001    Nevada\nName: state, dtype: object\n\n\n\nframe.iloc[0]#first row\n\nstate    Ohio\nyear     2000\npop       1.5\nName: 0, dtype: object\n\n\n\nframe3 = frame.set_index(\"state\", drop=False)\nprint(frame3)\n\n         state  year  pop\nstate                    \nOhio      Ohio  2000  1.5\nOhio      Ohio  2001  1.7\nOhio      Ohio  2002  3.6\nNevada  Nevada  2001  2.4\nNevada  Nevada  2002  2.9\nNevada  Nevada  2003  3.2\n\n\n\nframe3.loc[\"Ohio\"]\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      year\n      pop\n    \n    \n      state\n      \n      \n    \n  \n  \n    \n      Ohio\n      2000\n      1.5\n    \n    \n      Ohio\n      2001\n      1.7\n    \n    \n      Ohio\n      2002\n      3.6\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nframe.iloc[2001]# this does not work because we do not have 2001 rows !\n\n\nframe.iloc[0,1]\n\n2000\n\n\n\n\nAsking for columns\n\n#The columns are also an index:\nframe.columns\n\nIndex(['state', 'year', 'pop'], dtype='object')\n\n\nA column in a DataFrame can be retrieved MUCH easier: as a Series either by dictionary-like notation or by using the dot attribute notation:\n\nframe[\"state\"]\n\n0      Ohio\n1      Ohio\n2      Ohio\n3    Nevada\n4    Nevada\n5    Nevada\nName: state, dtype: object\n\n\n\nframe.year#equivalent to frame[\"year\"]\n\n0    2000\n1    2001\n2    2002\n3    2001\n4    2002\n5    2003\nName: year, dtype: int64\n\n\n\n\nSummary Stats\nJust like in numpy you can compute sums, means, counts and many other summaries along rows and columns, by specifying the axis argument:\n\nheight = np.array([1.79, 1.85, 1.95, 1.55])\nweight = np.array([70, 80, 85, 65])\nhw = np.array([height, weight]).transpose()\n\nhw\n\narray([[ 1.79, 70.  ],\n       [ 1.85, 80.  ],\n       [ 1.95, 85.  ],\n       [ 1.55, 65.  ]])\n\n\n\ndf = pd.DataFrame(hw, columns = [\"height\", \"weight\"]) \nprint(df)\n\n   height  weight\n0    1.79    70.0\n1    1.85    80.0\n2    1.95    85.0\n3    1.55    65.0\n\n\n\ndf = pd.DataFrame(hw , columns = [\"height\", \"weight\"],\n                  index = [\"Peter\", \"Matilda\", \"Bee\", \"Tom\"]) \nprint(df)\n\n         height  weight\nPeter      1.79    70.0\nMatilda    1.85    80.0\nBee        1.95    85.0\nTom        1.55    65.0\n\n\nCan you extract:\n\nAll weights\nPeter’s height\nBee’s full info\nthe average height\nget all persons with height greater than 180cm\n\n\n#see Lab5\n\n\nprint(df.mean(axis=0))\nprint(df.mean(axis=1))# are these averages sensible ?\n\nheight     1.785\nweight    75.000\ndtype: float64\nPeter      35.895\nMatilda    40.925\nBee        43.475\nBee        33.275\ndtype: float64\n\n\nSome methods are neither reductions nor accumulations. describe is one such example, producing multiple summary statistics in one shot:\n\ndf.describe()\n\n\n\n\n\n  \n    \n      \n      height\n      weight\n    \n  \n  \n    \n      count\n      4.000\n      4.000000\n    \n    \n      mean\n      1.785\n      75.000000\n    \n    \n      std\n      0.170\n      9.128709\n    \n    \n      min\n      1.550\n      65.000000\n    \n    \n      25%\n      1.730\n      68.750000\n    \n    \n      50%\n      1.820\n      75.000000\n    \n    \n      75%\n      1.875\n      81.250000\n    \n    \n      max\n      1.950\n      85.000000"
  },
  {
    "objectID": "IntroCoding_Lecture4.html#built-in-data-sets",
    "href": "IntroCoding_Lecture4.html#built-in-data-sets",
    "title": "5  Intro to pandas",
    "section": "Built in data sets",
    "text": "Built in data sets"
  },
  {
    "objectID": "IntroCoding_Lecture4.html#gapminder-data",
    "href": "IntroCoding_Lecture4.html#gapminder-data",
    "title": "5  Intro to pandas",
    "section": "Gapminder Data",
    "text": "Gapminder Data\nhttps://www.gapminder.org/fw/world-health-chart/\nhttps://www.ted.com/talks/hans_rosling_the_best_stats_you_ve_ever_seen#t-241405\n\nYou’ve never seen data presented like this. With the drama and urgency of a sportscaster, statistics guru Hans Rosling debunks myths about the so-called “developing world.”\n\n\n!pip install gapminder\n#!conda install gapminder\nfrom gapminder import gapminder\n#gapminder.to_csv(\"../datasets/gapminder.csv\")\n\n\ngapminder\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n    \n  \n  \n    \n      0\n      Afghanistan\n      Asia\n      1952\n      28.801\n      8425333\n      779.445314\n    \n    \n      1\n      Afghanistan\n      Asia\n      1957\n      30.332\n      9240934\n      820.853030\n    \n    \n      2\n      Afghanistan\n      Asia\n      1962\n      31.997\n      10267083\n      853.100710\n    \n    \n      3\n      Afghanistan\n      Asia\n      1967\n      34.020\n      11537966\n      836.197138\n    \n    \n      4\n      Afghanistan\n      Asia\n      1972\n      36.088\n      13079460\n      739.981106\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1699\n      Zimbabwe\n      Africa\n      1987\n      62.351\n      9216418\n      706.157306\n    \n    \n      1700\n      Zimbabwe\n      Africa\n      1992\n      60.377\n      10704340\n      693.420786\n    \n    \n      1701\n      Zimbabwe\n      Africa\n      1997\n      46.809\n      11404948\n      792.449960\n    \n    \n      1702\n      Zimbabwe\n      Africa\n      2002\n      39.989\n      11926563\n      672.038623\n    \n    \n      1703\n      Zimbabwe\n      Africa\n      2007\n      43.487\n      12311143\n      469.709298\n    \n  \n\n1704 rows × 6 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#find the unique years\n\n#get the years:\ngapminder[\"year\"]\nnp.unique(gapminder.year)\n\narray([1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002,\n       2007])\n\n\n\n#get all rows with year 1952:\n#Hint:\n#either use Boolean subsetting\ngapminder[\"year\"] == 1952\ngapminder[gapminder[\"year\"] == 1952]\n#or use an index !!\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n    \n  \n  \n    \n      0\n      Afghanistan\n      Asia\n      1952\n      28.801\n      8425333\n      779.445314\n    \n    \n      12\n      Albania\n      Europe\n      1952\n      55.230\n      1282697\n      1601.056136\n    \n    \n      24\n      Algeria\n      Africa\n      1952\n      43.077\n      9279525\n      2449.008185\n    \n    \n      36\n      Angola\n      Africa\n      1952\n      30.015\n      4232095\n      3520.610273\n    \n    \n      48\n      Argentina\n      Americas\n      1952\n      62.485\n      17876956\n      5911.315053\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1644\n      Vietnam\n      Asia\n      1952\n      40.412\n      26246839\n      605.066492\n    \n    \n      1656\n      West Bank and Gaza\n      Asia\n      1952\n      43.160\n      1030585\n      1515.592329\n    \n    \n      1668\n      Yemen, Rep.\n      Asia\n      1952\n      32.548\n      4963829\n      781.717576\n    \n    \n      1680\n      Zambia\n      Africa\n      1952\n      42.038\n      2672000\n      1147.388831\n    \n    \n      1692\n      Zimbabwe\n      Africa\n      1952\n      48.451\n      3080907\n      406.884115\n    \n  \n\n142 rows × 6 columns"
  },
  {
    "objectID": "IntroCoding_Lecture4.html#handling-files",
    "href": "IntroCoding_Lecture4.html#handling-files",
    "title": "5  Intro to pandas",
    "section": "Handling Files",
    "text": "Handling Files\nGet to know your friends\n\npd.read_csv\npd.read_table\npd.read_excel\n\n\n'''url = \"https://drive.google.com/file/d/1oIvCdN15UEwt4dCyjkArekHnTrivN43v/view?usp=share_link\"\nurl='https://drive.google.com/uc?id=' + url.split('/')[-2]\ngapminder = pd.read_csv(url, index_col=0)\ngapminder.head()'''\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n    \n  \n  \n    \n      0\n      Afghanistan\n      Asia\n      1952\n      28.801\n      8425333\n      779.445314\n    \n    \n      1\n      Afghanistan\n      Asia\n      1957\n      30.332\n      9240934\n      820.853030\n    \n    \n      2\n      Afghanistan\n      Asia\n      1962\n      31.997\n      10267083\n      853.100710\n    \n    \n      3\n      Afghanistan\n      Asia\n      1967\n      34.020\n      11537966\n      836.197138\n    \n    \n      4\n      Afghanistan\n      Asia\n      1972\n      36.088\n      13079460\n      739.981106\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ngapminder.sort_values(by=\"year\").head()\n\n\n\n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n    \n  \n  \n    \n      0\n      Afghanistan\n      Asia\n      1952\n      28.801\n      8425333\n      779.445314\n    \n    \n      528\n      France\n      Europe\n      1952\n      67.410\n      42459667\n      7029.809327\n    \n    \n      540\n      Gabon\n      Africa\n      1952\n      37.003\n      420702\n      4293.476475\n    \n    \n      1656\n      West Bank and Gaza\n      Asia\n      1952\n      43.160\n      1030585\n      1515.592329\n    \n    \n      552\n      Gambia\n      Africa\n      1952\n      30.000\n      284320\n      485.230659\n    \n  \n\n\n\n\n\n#How many countries?\nCtryCts = gapminder[\"country\"].value_counts()\nCtryCts\n#note the similarity with np.unique(..., return_counts=True)\n\nAfghanistan          12\nPakistan             12\nNew Zealand          12\nNicaragua            12\nNiger                12\n                     ..\nEritrea              12\nEquatorial Guinea    12\nEl Salvador          12\nEgypt                12\nZimbabwe             12\nName: country, Length: 142, dtype: int64\n\n\n\nfrom numpy.random import default_rng\nrng = default_rng()\nrng.choice(gapminder[\"country\"].unique(),2)\ngapminder[\"year\"].unique()\n\narray([1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 1997, 2002,\n       2007])\n\n\n\n#How meaningful are the column stats?\nprint(gapminder.mean(axis=0))\ngapminder.describe()\n\nyear         1.979500e+03\nlifeExp      5.947444e+01\npop          2.960121e+07\ngdpPercap    7.215327e+03\ndtype: float64\n\n\n/var/folders/h4/k73g68ds6xj791sf8cpmlxlc0000gn/T/ipykernel_33611/633466148.py:2: FutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  print(gapminder.mean(axis=0))\n\n\n\n\n\n\n  \n    \n      \n      year\n      lifeExp\n      pop\n      gdpPercap\n    \n  \n  \n    \n      count\n      1704.00000\n      1704.000000\n      1.704000e+03\n      1704.000000\n    \n    \n      mean\n      1979.50000\n      59.474439\n      2.960121e+07\n      7215.327081\n    \n    \n      std\n      17.26533\n      12.917107\n      1.061579e+08\n      9857.454543\n    \n    \n      min\n      1952.00000\n      23.599000\n      6.001100e+04\n      241.165876\n    \n    \n      25%\n      1965.75000\n      48.198000\n      2.793664e+06\n      1202.060309\n    \n    \n      50%\n      1979.50000\n      60.712500\n      7.023596e+06\n      3531.846988\n    \n    \n      75%\n      1993.25000\n      70.845500\n      1.958522e+07\n      9325.462346\n    \n    \n      max\n      2007.00000\n      82.603000\n      1.318683e+09\n      113523.132900\n    \n  \n\n\n\n\nSort the index before you slice!!\nChoose a time range and specific countries\n\ngapminder2 = gapminder.set_index(\"year\").sort_index()\ngap1982_92 = gapminder2.loc[1982:1992].reset_index()\ngap1982_92 = gap1982_92.set_index(\"country\").sort_index()\ngap1982_92.loc[\"Afghanistan\":\"Albania\"]\n\n\n\n\n\n  \n    \n      \n      year\n      continent\n      lifeExp\n      pop\n      gdpPercap\n    \n    \n      country\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      Afghanistan\n      1982\n      Asia\n      39.854\n      12881816\n      978.011439\n    \n    \n      Afghanistan\n      1987\n      Asia\n      40.822\n      13867957\n      852.395945\n    \n    \n      Afghanistan\n      1992\n      Asia\n      41.674\n      16317921\n      649.341395\n    \n    \n      Albania\n      1992\n      Europe\n      71.581\n      3326498\n      2497.437901\n    \n    \n      Albania\n      1987\n      Europe\n      72.000\n      3075321\n      3738.932735\n    \n    \n      Albania\n      1982\n      Europe\n      70.420\n      2780097\n      3630.880722\n    \n  \n\n\n\n\n\ngap1982_92.loc[\"Afghanistan\":\"Albania\",\"lifeExp\"].mean()\n\n56.0585"
  },
  {
    "objectID": "IntroCoding_Lecture5.html",
    "href": "IntroCoding_Lecture5.html",
    "title": "6  Data Summaries",
    "section": "",
    "text": "In this lecture we will get to know and become experts in: 1. Data Manipulation with pandas * Handling Files * Counting and Summary Statistics * Grouped Operations 2. Plotting * matplotlib * pandas\nAnd if you want to delve deeper, look at the Advanced topics\nRelevant DataCamp lessons:"
  },
  {
    "objectID": "IntroCoding_Lecture5.html#data-manipulation-with-pandas",
    "href": "IntroCoding_Lecture5.html#data-manipulation-with-pandas",
    "title": "6  Data Summaries",
    "section": "Data Manipulation with pandas",
    "text": "Data Manipulation with pandas\nWhile we have seen panda’s ability to (i) mix data types (strings, numbers, categories, Boolean, …) and (ii) refer to columns and rows by names, this library offers a lot more powerful tools for efficiently gaining insights from data, e.g.\n\nsummarize/aggregate data in efficient pivot style manners\nhandling missing values\nvisualize/plot data\n\n\n!pip install gapminder\nfrom gapminder import gapminder"
  },
  {
    "objectID": "IntroCoding_Lecture5.html#handling-files",
    "href": "IntroCoding_Lecture5.html#handling-files",
    "title": "6  Data Summaries",
    "section": "Handling Files",
    "text": "Handling Files\nGet to know your friends\n\npd.read_csv\npd.read_table\npd.read_excel\n\nBut before that we need to connect to our Google drives ! (more instructions can be found here)\n\n\"Sam\" + \" Altman\" \n\n'Sam Altman'\n\n\nCounting and Summary Statistics\n\ngapminder.sort_values(by=\"year\").head()\n\n\n\n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n    \n  \n  \n    \n      0\n      Afghanistan\n      Asia\n      1952\n      28.801\n      8425333\n      779.445314\n    \n    \n      528\n      France\n      Europe\n      1952\n      67.410\n      42459667\n      7029.809327\n    \n    \n      540\n      Gabon\n      Africa\n      1952\n      37.003\n      420702\n      4293.476475\n    \n    \n      1656\n      West Bank and Gaza\n      Asia\n      1952\n      43.160\n      1030585\n      1515.592329\n    \n    \n      552\n      Gambia\n      Africa\n      1952\n      30.000\n      284320\n      485.230659\n    \n  \n\n\n\n\n\n#How many countries?\nCtryCts = gapminder[\"country\"].value_counts()\nCtryCts\n#note the similarity with np.unique(..., return_counts=True)\n\nAfghanistan          12\nPakistan             12\nNew Zealand          12\nNicaragua            12\nNiger                12\n                     ..\nEritrea              12\nEquatorial Guinea    12\nEl Salvador          12\nEgypt                12\nZimbabwe             12\nName: country, Length: 142, dtype: int64"
  },
  {
    "objectID": "IntroCoding_Lecture5.html#grouped-operations",
    "href": "IntroCoding_Lecture5.html#grouped-operations",
    "title": "6  Data Summaries",
    "section": "Grouped Operations",
    "text": "Grouped Operations\nThe gapminder data is a good example for wanting to apply functions to subsets to data that correspond to categories, e.g. * by year * by country * by continent\nThe powerful pandas .groupby() method enables exactly this goal rather elegantly and efficiently.\nFirst, think how you could possibly compute the average GDP seprataley for each continent. The numpy.mean(..., axis=...) will not help you.\nInstead you will have to manually find all continents and then use Boolean logic:\n\ncontinents =np.unique(gapminder[\"continent\"])\ncontinents\n\narray(['Africa', 'Americas', 'Asia', 'Europe', 'Oceania'], dtype=object)\n\n\n\nAfricaRows = gapminder[\"continent\"]==\"Africa\"\ngapminder[AfricaRows][\"gdpPercap\"].mean()\n\n\n#you could use a for loop instead, of course\ngapminder[gapminder[\"continent\"]==\"Africa\"][\"gdpPercap\"].mean()\ngapminder[gapminder[\"continent\"]==\"Americas\"][\"gdpPercap\"].mean()\ngapminder[gapminder[\"continent\"]==\"Asia\"][\"gdpPercap\"].mean()\ngapminder[gapminder[\"continent\"]==\"Europe\"][\"gdpPercap\"].mean()\ngapminder[gapminder[\"continent\"]==\"Oceania\"][\"gdpPercap\"].mean()\n\n18621.609223333333\n\n\nInstead, we should embrace the concept of grouping by a variable\n\ngapminder.mean()\n\nFutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  gapminder.mean()\n\n\nyear         1.979500e+03\nlifeExp      5.947444e+01\npop          2.960121e+07\ngdpPercap    7.215327e+03\ndtype: float64\n\n\n\nbyContinent = gapminder.groupby(\"continent\")\nbyContinent.mean()\n\nFutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n  byContinent.mean()\n\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      year\n      lifeExp\n      pop\n      gdpPercap\n    \n    \n      continent\n      \n      \n      \n      \n    \n  \n  \n    \n      Africa\n      1979.5\n      48.865330\n      9.916003e+06\n      2193.754578\n    \n    \n      Americas\n      1979.5\n      64.658737\n      2.450479e+07\n      7136.110356\n    \n    \n      Asia\n      1979.5\n      60.064903\n      7.703872e+07\n      7902.150428\n    \n    \n      Europe\n      1979.5\n      71.903686\n      1.716976e+07\n      14469.475533\n    \n    \n      Oceania\n      1979.5\n      74.326208\n      8.874672e+06\n      18621.609223\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#only lifeExp:\nbyContinent[\"lifeExp\"].max()\n#maybe there is more to life than the mean\n\n76.442\n\n\n\nbyContinent[\"gdpPercap\"].agg([min,max, np.mean])\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      min\n      max\n      mean\n    \n    \n      continent\n      \n      \n      \n    \n  \n  \n    \n      Africa\n      241.165876\n      21951.21176\n      2193.754578\n    \n    \n      Americas\n      1201.637154\n      42951.65309\n      7136.110356\n    \n    \n      Asia\n      331.000000\n      113523.13290\n      7902.150428\n    \n    \n      Europe\n      973.533195\n      49357.19017\n      14469.475533\n    \n    \n      Oceania\n      10039.595640\n      34435.36744\n      18621.609223\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#multiple aggregating functions (no built in function mean)\ngapminder.groupby(\"continent\")[\"gdpPercap\"].agg([min,max, np.mean])\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      min\n      max\n      mean\n    \n    \n      continent\n      \n      \n      \n    \n  \n  \n    \n      Africa\n      241.165876\n      21951.21176\n      2193.754578\n    \n    \n      Americas\n      1201.637154\n      42951.65309\n      7136.110356\n    \n    \n      Asia\n      331.000000\n      113523.13290\n      7902.150428\n    \n    \n      Europe\n      973.533195\n      49357.19017\n      14469.475533\n    \n    \n      Oceania\n      10039.595640\n      34435.36744\n      18621.609223\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nbyContinentYear = gapminder.groupby([\"continent\", \"year\"])[\"gdpPercap\"]\nbyContinentYear.mean()\n\n\n#multiple keys\ngapminder[\"past1990\"] = gapminder[\"year\"] > 1990\nbyContinentYear = gapminder.groupby([\"continent\", \"past1990\"])[\"gdpPercap\"]\nbyContinentYear.mean()\n\ncontinent  past1990\nAfrica     False        1997.008411\n           True         2587.246913\nAmericas   False        6051.047533\n           True         9306.236000\nAsia       False        6713.113041\n           True        10280.225202\nEurope     False       11341.142807\n           True        20726.140986\nOceania    False       15224.015414\n           True        25416.796842\nName: gdpPercap, dtype: float64\n\n\n\n\nTitanic data\n\n# Since pandas does not have any built in data, I am going to \"cheat\" and \n# make use of the `seaborn` library\nimport seaborn as sns \n\ntitanic = sns. load_dataset('titanic')\ntitanic[\"3rdClass\"] = titanic[\"pclass\"]==3\ntitanic[\"male\"] = titanic[\"sex\"]==\"male\"\n\ntitanic\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      survived\n      pclass\n      sex\n      age\n      sibsp\n      parch\n      fare\n      embarked\n      class\n      who\n      adult_male\n      deck\n      embark_town\n      alive\n      alone\n      3rdClass\n      male\n    \n  \n  \n    \n      0\n      0\n      3\n      male\n      22.0\n      1\n      0\n      7.2500\n      S\n      Third\n      man\n      True\n      NaN\n      Southampton\n      no\n      False\n      True\n      True\n    \n    \n      1\n      1\n      1\n      female\n      38.0\n      1\n      0\n      71.2833\n      C\n      First\n      woman\n      False\n      C\n      Cherbourg\n      yes\n      False\n      False\n      False\n    \n    \n      2\n      1\n      3\n      female\n      26.0\n      0\n      0\n      7.9250\n      S\n      Third\n      woman\n      False\n      NaN\n      Southampton\n      yes\n      True\n      True\n      False\n    \n    \n      3\n      1\n      1\n      female\n      35.0\n      1\n      0\n      53.1000\n      S\n      First\n      woman\n      False\n      C\n      Southampton\n      yes\n      False\n      False\n      False\n    \n    \n      4\n      0\n      3\n      male\n      35.0\n      0\n      0\n      8.0500\n      S\n      Third\n      man\n      True\n      NaN\n      Southampton\n      no\n      True\n      True\n      True\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      886\n      0\n      2\n      male\n      27.0\n      0\n      0\n      13.0000\n      S\n      Second\n      man\n      True\n      NaN\n      Southampton\n      no\n      True\n      False\n      True\n    \n    \n      887\n      1\n      1\n      female\n      19.0\n      0\n      0\n      30.0000\n      S\n      First\n      woman\n      False\n      B\n      Southampton\n      yes\n      True\n      False\n      False\n    \n    \n      888\n      0\n      3\n      female\n      NaN\n      1\n      2\n      23.4500\n      S\n      Third\n      woman\n      False\n      NaN\n      Southampton\n      no\n      False\n      True\n      False\n    \n    \n      889\n      1\n      1\n      male\n      26.0\n      0\n      0\n      30.0000\n      C\n      First\n      man\n      True\n      C\n      Cherbourg\n      yes\n      True\n      False\n      True\n    \n    \n      890\n      0\n      3\n      male\n      32.0\n      0\n      0\n      7.7500\n      Q\n      Third\n      man\n      True\n      NaN\n      Queenstown\n      no\n      True\n      True\n      True\n    \n  \n\n891 rows × 17 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#overall survival rate\ntitanic.survived.mean()\n\n0.3838383838383838\n\n\nTasks:\n\ncompute the proportion of survived separately for\n\nmale/female\nthe three classes\nPclass and sex\n\ncompute the mean age separately for male/female\n\n\n#I would like to compute the mean survical seprately for each group\nbySex = titanic.groupby(\"sex\")\n#here I am specifically asking for the mean\nbySex[\"survived\"].mean()\n#if you want multiple summaries, you can list them all inside the agg():\nbySex[\"survived\"].agg([min, max, np.mean ])\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      min\n      max\n      mean\n    \n    \n      sex\n      \n      \n      \n    \n  \n  \n    \n      female\n      0\n      1\n      0.742038\n    \n    \n      male\n      0\n      1\n      0.188908\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#I would like to compute the mean survical seprately for each group\nbySexPclass = titanic.groupby([\"pclass\", \"sex\"])\n#here I am specifically asking for the mean\nbySexPclass[\"survived\"].mean()\n\npclass  sex   \n1       female    0.968085\n        male      0.368852\n2       female    0.921053\n        male      0.157407\n3       female    0.500000\n        male      0.135447\nName: survived, dtype: float64\n\n\n\nbySex = titanic.groupby(\"sex\")\n#here I am specifically asking for the mean\nbySex[\"survived\"].mean()"
  },
  {
    "objectID": "IntroCoding_Lecture5.html#plotting",
    "href": "IntroCoding_Lecture5.html#plotting",
    "title": "6  Data Summaries",
    "section": "Plotting",
    "text": "Plotting\nWe will not spend much time with basic plots in matplotlib but instead move quickly toward the pandas versions of these functions.\n\n#%matplotlib inline\nimport matplotlib.pyplot as plt\n\n#plt.rcParams['figure.dpi'] = 800\nyear = [1950, 1970, 1990, 2010]\npop = [2.519, 3.692, 5.263, 6.972]\nplt.plot(year, pop)\n#plt.bar(year, pop)\n#plt.scatter(year, pop)\nplt.xlabel('Year')\nplt.ylabel('Population')\nplt.title('World Population')\nx = 1\n#plt.show()\n\n\n\n\npandas offers plots directly from its objects\n\ntitanic.age.hist()\nplt.show()\n\n\n\n\nAnd often the axis labels are taken care of\n\n#titanic.groupby(\"pclass\").survived.mean().plot.bar()\nSurvByPclass = titanic.groupby(\"pclass\").survived.mean()\n\nSurvByPclass.plot(kind=\"bar\", title = \"Mean Survival\");\n\n<Axes: title={'center': 'Mean Survival'}, xlabel='pclass'>\n\n\n\n\n\nBut you can customize each plot as you wish:\n\nSurvByPclass.plot(kind=\"bar\", x = \"Passenger Class\", y = \"Survived\", title = \"Mean Survival\");\n\n<Axes: title={'center': 'Mean Survival'}, xlabel='pclass'>\n\n\n\n\n\nTasks:\n\nCompute the avg. life expectancy in the gapminder data for each year\nPlot this as a line plot and give meaningful x and y labels and a title\n\n\nlifeExpbyYear = gapminder.groupby(\"year\")[\"lifeExp\"].mean()\n\nlifeExpbyYear.plot(y= \"avg. life Exp\", title = \"Average life Expectancvy per year\");\n\n<Axes: title={'center': 'Average life Expectancvy per year'}, xlabel='year'>"
  },
  {
    "objectID": "IntroCoding_Lecture5.html#advanced-topics",
    "href": "IntroCoding_Lecture5.html#advanced-topics",
    "title": "6  Data Summaries",
    "section": "Advanced topics",
    "text": "Advanced topics\n\nCreating Dataframes\n\nZip\nFrom list of dicts\n\n\n\nIndexing:\n\nmultilevel indexes\nsorting\nasking for ranges"
  },
  {
    "objectID": "IntroCoding_Lecture5.html#types-of-columns",
    "href": "IntroCoding_Lecture5.html#types-of-columns",
    "title": "6  Data Summaries",
    "section": "Types of columns",
    "text": "Types of columns\n\ncategorical\ndates\n\n\n# Creating Dataframes\n#using zip\n# List1\nName = ['tom', 'krish', 'nick', 'juli']\n  \n# List2\nAge = [25, 30, 26, 22]\n  \n# get the list of tuples from two lists.\n# and merge them by using zip().\nlist_of_tuples = list(zip(Name, Age))\nlist_of_tuples = zip(Name, Age)\n# Assign data to tuples.\n#print(list_of_tuples)\n  \n  \n# Converting lists of tuples into\n# pandas Dataframe.\ndf = pd.DataFrame(list_of_tuples,\n                  columns=['Name', 'Age'])\n  \n# Print data.\ndf\n\n\n\n\n\n  \n    \n      \n      Name\n      Age\n    \n  \n  \n    \n      0\n      tom\n      25\n    \n    \n      1\n      krish\n      30\n    \n    \n      2\n      nick\n      26\n    \n    \n      3\n      juli\n      22\n    \n  \n\n\n\n\n\n#from list of dicts\ndata = [{'a': 1, 'b': 2, 'c': 3},\n        {'a': 10, 'b': 20, 'c': 30}]\n  \n# Creates DataFrame.\ndf = pd.DataFrame(data)\n  \ndf\n\n\n\n\n\n  \n    \n      \n      a\n      b\n      c\n    \n  \n  \n    \n      0\n      1\n      2\n      3\n    \n    \n      1\n      10\n      20\n      30\n    \n  \n\n\n\n\n\n# Indexing:\n\nadvLesson = True\nif advLesson:\n    frame2 = frame.set_index([\"year\", \"state\"])\n    print(frame2)\n    frame3 = frame2.sort_index()\n    print(frame3)\n    print(frame.loc[:,\"state\":\"year\"])\n\n             pop\nyear state      \n2000 Ohio    1.5\n2001 Ohio    1.7\n2002 Ohio    3.6\n2001 Nevada  2.4\n2002 Nevada  2.9\n2003 Nevada  3.2\n             pop\nyear state      \n2000 Ohio    1.5\n2001 Nevada  2.4\n     Ohio    1.7\n2002 Nevada  2.9\n     Ohio    3.6\n2003 Nevada  3.2\n    state  year\n0    Ohio  2000\n1    Ohio  2001\n2    Ohio  2002\n3  Nevada  2001\n4  Nevada  2002\n5  Nevada  2003\n\n\n\nInplace\nNote that I reassigned the objects in the code above. That is because most operations, such as set_index, sort_index, drop, etc. do not operate inplace unless specified!"
  },
  {
    "objectID": "IntroCoding_Lecture6.html",
    "href": "IntroCoding_Lecture6.html",
    "title": "7  Missing Values/Duplicates",
    "section": "",
    "text": "In this lecture we will continue our journey of Data Manipulation with pandas after reviewing some fundamental aspects of the syntax"
  },
  {
    "objectID": "IntroCoding_Lecture6.html#plotting",
    "href": "IntroCoding_Lecture6.html#plotting",
    "title": "7  Missing Values/Duplicates",
    "section": "Plotting",
    "text": "Plotting\nThe “plot type of the day” is one of the most popular ones used to display data distributions, the boxplot.\nBoxplots, also known as box-and-whisker plots, are a statistical visualization tool that provides a concise summary of a dataset’s distribution. They display key descriptive statistics and provide insights into the central tendency, variability, and skewness of the data. Here’s a brief introduction and motivation for using boxplots:\n\nStructure of Boxplots: Boxplots consist of a box and whiskers that represent different statistical measures of the data:\n\nThe box represents the interquartile range (IQR), which spans from the lower quartile (25th percentile) to the upper quartile (75th percentile). The width of the box indicates the spread of the middle 50% of the data.\nA line (whisker) extends from each end of the box to show the minimum and maximum values within a certain range (often defined as 1.5 times the IQR).\nPoints beyond the whiskers are considered outliers and plotted individually.\n\nMotivation for Using Boxplots: Boxplots offer several benefits and are commonly used for the following reasons:\n\nVisualizing Data Distribution: Boxplots provide a concise overview of the distribution of a dataset. They show the skewness, symmetry, and presence of outliers, allowing for quick identification of key features.\nComparing Groups: Boxplots enable easy visual comparison of multiple groups or categories. By placing side-by-side boxplots, you can assess differences in central tendency and variability between groups.\nOutlier Detection: Boxplots explicitly mark outliers, aiding in the identification of extreme values or data points that deviate significantly from the overall pattern.\nData Summary: Boxplots summarize key statistics, including the median, quartiles, and range, providing a quick understanding of the dataset without the need for detailed calculations.\nRobustness: Boxplots are relatively robust to skewed or asymmetric data and can effectively handle datasets with outliers.\n\n\nBoxplots are widely used in various fields, including data analysis, exploratory data visualization, and statistical reporting. They offer a clear and concise representation of data distribution, making them a valuable tool for understanding and communicating the characteristics of a dataset.\n\n!pip install gapminder\nfrom gapminder import gapminder\n\n\ngapminder\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n    \n  \n  \n    \n      0\n      Afghanistan\n      Asia\n      1952\n      28.801\n      8425333\n      779.445314\n    \n    \n      1\n      Afghanistan\n      Asia\n      1957\n      30.332\n      9240934\n      820.853030\n    \n    \n      2\n      Afghanistan\n      Asia\n      1962\n      31.997\n      10267083\n      853.100710\n    \n    \n      3\n      Afghanistan\n      Asia\n      1967\n      34.020\n      11537966\n      836.197138\n    \n    \n      4\n      Afghanistan\n      Asia\n      1972\n      36.088\n      13079460\n      739.981106\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      1699\n      Zimbabwe\n      Africa\n      1987\n      62.351\n      9216418\n      706.157306\n    \n    \n      1700\n      Zimbabwe\n      Africa\n      1992\n      60.377\n      10704340\n      693.420786\n    \n    \n      1701\n      Zimbabwe\n      Africa\n      1997\n      46.809\n      11404948\n      792.449960\n    \n    \n      1702\n      Zimbabwe\n      Africa\n      2002\n      39.989\n      11926563\n      672.038623\n    \n    \n      1703\n      Zimbabwe\n      Africa\n      2007\n      43.487\n      12311143\n      469.709298\n    \n  \n\n1704 rows × 6 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\nThe pandas way\n\ngapminder.boxplot(column = \"lifeExp\", by=\"continent\");\n\n\n\n\nThe matplotlib way\n\nplt.boxplot(gapminder[\"continent\"], gapminder[\"lifeExp\"]);\n\n\nTask\n\nCreate a boxplot for gdpPercap instead. What do you notice ? Are you happy with how the plot looks? Any “trick” you can think to make this more readable?\nAdvanced: can you create boxplots for gdpPerCap and lifeExp in one command?\n\n\ngapminder.boxplot(column = \"gdpPercap\", by=\"continent\");\nplt.yscale(\"log\")\n\n\n\n\n\nFurther Reading:\n\nPython Plotting With Matplotlib Tutorial.)\n\n\nimport numpy as np\nfrom scipy.stats import entropy\n\np = np.array([1/100, 99/100])\nn=2\n#p = np.array(np.ones)/n\nH = entropy(p, base=2)\nH\n\n0.08079313589591118"
  },
  {
    "objectID": "IntroCoding_Lecture7.html",
    "href": "IntroCoding_Lecture7.html",
    "title": "8  Intro to Models",
    "section": "",
    "text": "In this lecture we will learn about modeling data for the first time. After this lesson, you should know what we generally mean by a “model”, what linear regression is and how to interpret the output. But first we need to introduce a new data type: categorical variables.\nOnline Resources:\nChapter 7.5 of our textbook introduces categorical variables."
  },
  {
    "objectID": "IntroCoding_Lecture7.html#categorical-variables",
    "href": "IntroCoding_Lecture7.html#categorical-variables",
    "title": "8  Intro to Models",
    "section": "Categorical variables",
    "text": "Categorical variables\nAs a motivation, take another look at the gapminder data which contains variables of a mixed type: numeric columns along with string type columns which contain repeated instances of a smaller set of distinct or discrete values which\n\nare not numeric (but could be represented as numbers)\ncannot really be ordered\ntypically take on a finite set of values, or categories.\n\nWe refer to these data types as categorical.\nWe have already seen functions like unique and value_counts, which enable us to extract the distinct values from an array and compute their frequencies.\nBoxplots and grouping operations typically use a categorical variable to compute summaries of a numerical variables for each category separately, e.g.\n\ngapminder.boxplot(column = \"lifeExp\", by=\"continent\",figsize=(5, 2));\nplt.title('Life expectancy by continent')\n# Remove the default suptitle\nplt.suptitle(\"\");\n\n\n\n\npandas has a special Categorical extension type for holding data that uses the integer-based categorical representation or encoding. This is a popular data compression technique for data with many occurrences of similar values and can provide significantly faster performance with lower memory use, especially for string data.\n\ngapminder.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1704 entries, 0 to 1703\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   country    1704 non-null   object \n 1   continent  1704 non-null   object \n 2   year       1704 non-null   int64  \n 3   lifeExp    1704 non-null   float64\n 4   pop        1704 non-null   int64  \n 5   gdpPercap  1704 non-null   float64\ndtypes: float64(2), int64(2), object(2)\nmemory usage: 80.0+ KB\n\n\n\ngapminder['country'] = gapminder['country'].astype('category')\ngapminder.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1704 entries, 0 to 1703\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype   \n---  ------     --------------  -----   \n 0   country    1704 non-null   category\n 1   continent  1704 non-null   object  \n 2   year       1704 non-null   int64   \n 3   lifeExp    1704 non-null   float64 \n 4   pop        1704 non-null   int64   \n 5   gdpPercap  1704 non-null   float64 \ndtypes: category(1), float64(2), int64(2), object(1)\nmemory usage: 75.2+ KB\n\n\nWe will come back to the usefulness of this later."
  },
  {
    "objectID": "IntroCoding_Lecture7.html#tables-as-models",
    "href": "IntroCoding_Lecture7.html#tables-as-models",
    "title": "8  Intro to Models",
    "section": "Tables as models",
    "text": "Tables as models\nFor now let us look at our first “model”:\n\ntitanic = sns.load_dataset('titanic')\ntitanic[\"class3\"] = (titanic[\"pclass\"]==3)\ntitanic[\"male\"] = (titanic[\"sex\"]==\"male\")\ntitanic.head()\n\n\n\n\n\n  \n    \n      \n      survived\n      pclass\n      sex\n      age\n      sibsp\n      parch\n      fare\n      embarked\n      class\n      who\n      adult_male\n      deck\n      embark_town\n      alive\n      alone\n      class3\n      male\n    \n  \n  \n    \n      0\n      0\n      3\n      male\n      22.0\n      1\n      0\n      7.2500\n      S\n      Third\n      man\n      True\n      NaN\n      Southampton\n      no\n      False\n      True\n      True\n    \n    \n      1\n      1\n      1\n      female\n      38.0\n      1\n      0\n      71.2833\n      C\n      First\n      woman\n      False\n      C\n      Cherbourg\n      yes\n      False\n      False\n      False\n    \n    \n      2\n      1\n      3\n      female\n      26.0\n      0\n      0\n      7.9250\n      S\n      Third\n      woman\n      False\n      NaN\n      Southampton\n      yes\n      True\n      True\n      False\n    \n    \n      3\n      1\n      1\n      female\n      35.0\n      1\n      0\n      53.1000\n      S\n      First\n      woman\n      False\n      C\n      Southampton\n      yes\n      False\n      False\n      False\n    \n    \n      4\n      0\n      3\n      male\n      35.0\n      0\n      0\n      8.0500\n      S\n      Third\n      man\n      True\n      NaN\n      Southampton\n      no\n      True\n      True\n      True\n    \n  \n\n\n\n\n\nvals1, cts1 = np.unique(titanic[\"class3\"], return_counts=True)\nprint(cts1)\nprint(vals1)\n\n[400 491]\n[False  True]\n\n\n\nprint(\"The mean survival on the Titanic was\", np.mean(titanic.survived))\n\nThe mean survival on the Titanic was 0.3838383838383838\n\n\n\nConTbl = pd.crosstab(titanic[\"sex\"], titanic[\"survived\"])\nConTbl\n\n\n\n\n\n  \n    \n      survived\n      0\n      1\n    \n    \n      sex\n      \n      \n    \n  \n  \n    \n      female\n      81\n      233\n    \n    \n      male\n      468\n      109\n    \n  \n\n\n\n\nWhat are the estimated survival probabilities?\n\n#the good old groupby way:\nbySex = titanic.groupby(\"sex\").survived\nbySex.mean()\n\nsex\nfemale    0.742038\nmale      0.188908\nName: survived, dtype: float64\n\n\n\np3D = pd.crosstab([titanic[\"sex\"], titanic[\"class3\"]], titanic[\"survived\"])\np3D\n\n\n\n\n\n  \n    \n      \n      survived\n      0\n      1\n    \n    \n      sex\n      class3\n      \n      \n    \n  \n  \n    \n      female\n      False\n      9\n      161\n    \n    \n      True\n      72\n      72\n    \n    \n      male\n      False\n      168\n      62\n    \n    \n      True\n      300\n      47\n    \n  \n\n\n\n\nWhat are the estimated survival probabilities?\n\n#the good old groupby way:\nbySex = titanic.groupby([\"sex\", \"class3\"]).survived\nbySex.mean()\n\nsex     class3\nfemale  False     0.947059\n        True      0.500000\nmale    False     0.269565\n        True      0.135447\nName: survived, dtype: float64\n\n\nThe above table can be looked at as a model, which is defined as a function which takes inputs x and “spits out” a prediction:\n\\(y = f(\\mathbf{x})\\)\nIn our case, the inputs are \\(x_1=\\text{sex}\\), \\(x_2=\\text{class3}\\), and the output is the estimated survival probability!\nIt is evident that we could keep adding more input variables and make finer and finer grained predictions.\n\nLinear Models\n\nlsFit = smf.ols('survived ~ sex:class3-1', titanic).fit()\nlsFit.summary().tables[1]\n\n\n\n\n                               coef     std err      t      P>|t|  [0.025    0.975]  \n\n\n  sex[female]:class3[False]     0.9471     0.029    32.200  0.000     0.889     1.005\n\n\n  sex[male]:class3[False]       0.2696     0.025    10.660  0.000     0.220     0.319\n\n\n  sex[female]:class3[True]      0.5000     0.032    15.646  0.000     0.437     0.563\n\n\n  sex[male]:class3[True]        0.1354     0.021     6.579  0.000     0.095     0.176\n\n\n\n\n\n\nModeling Missing Values\nWe have already seen how to detect and how to replace missing values. But the latter -until now- was rather crude: we often replaced all values with a “global” average.\nClearly, we can do better than replacing all missing entries in the survived column with the average \\(0.38\\).\n\nrng = default_rng()\n\nmissingRows = rng.integers(0,890,20)\nprint(missingRows)\n#introduce missing values\ntitanic.iloc[missingRows,0] = np.nan\nnp.sum(titanic.survived.isna())\n\n[864 299 857 182 808 817 802 295 255 644   1 685 452 463 303 551 517 502\n 495 412]\n\n\n20\n\n\n\npredSurv = lsFit.predict()\nprint( len(predSurv))\npredSurv[titanic.survived.isna()]\n\n891\n\n\narray([0.94705882, 0.13544669, 0.5       , 0.26956522, 0.94705882,\n       0.94705882, 0.94705882, 0.26956522, 0.26956522, 0.13544669,\n       0.5       , 0.13544669, 0.26956522, 0.5       , 0.26956522,\n       0.26956522, 0.26956522, 0.26956522, 0.26956522, 0.26956522])\n\n\n\nFrom categorical to numerical relations\n\nurl = \"https://drive.google.com/file/d/1UbZy5Ecknpl1GXZBkbhJ_K6GJcIA2Plq/view?usp=share_link\" \nurl='https://drive.google.com/uc?id=' + url.split('/')[-2]\nauto = pd.read_csv(url)\nauto.head()\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      mpg\n      cylinders\n      displacement\n      horsepower\n      weight\n      acceleration\n      year\n      origin\n      name\n      Manufacturer\n    \n  \n  \n    \n      0\n      18.0\n      8\n      307.0\n      130\n      3504\n      12.0\n      70\n      1\n      chevrolet chevelle malibu\n      chevrolet\n    \n    \n      1\n      15.0\n      8\n      350.0\n      165\n      3693\n      11.5\n      70\n      1\n      buick skylark 320\n      buick\n    \n    \n      2\n      18.0\n      8\n      318.0\n      150\n      3436\n      11.0\n      70\n      1\n      plymouth satellite\n      plymouth\n    \n    \n      3\n      16.0\n      8\n      304.0\n      150\n      3433\n      12.0\n      70\n      1\n      amc rebel sst\n      amc\n    \n    \n      4\n      17.0\n      8\n      302.0\n      140\n      3449\n      10.5\n      70\n      1\n      ford torino\n      ford\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nplt.figure(figsize=(5,3))\nplt.scatter(x=auto[\"weight\"], y=auto[\"mpg\"]);"
  },
  {
    "objectID": "IntroCoding_Lecture7.html#linear-regression",
    "href": "IntroCoding_Lecture7.html#linear-regression",
    "title": "8  Intro to Models",
    "section": "Linear Regression",
    "text": "Linear Regression\nWe can roughly estimate, i.e. “model” this relationship with a straight line:\n\\[\ny = \\beta_0 + \\beta_1 x\n\\]\n\nplt.figure(figsize=(5,3))\ntmp=sns.regplot(x=auto[\"weight\"], y=auto[\"mpg\"], order=1, ci=95, \n                scatter_kws={'color':'b', 's':9}, line_kws={'color':'r'})\n\n\n\n\nRemind yourself of the definition of the slope of a straight line\n\\[\n\\beta_1 = \\frac{\\Delta y}{\\Delta x} =  \\frac{y_2-y_1}{x_2-x_1}\n\\]\n\nest = smf.ols('mpg ~ weight', auto).fit()\nest.summary().tables[1]\n\n\n\n\n               coef     std err      t      P>|t|  [0.025    0.975]  \n\n\n  Intercept    46.2165     0.799    57.867  0.000    44.646    47.787\n\n\n  weight       -0.0076     0.000   -29.645  0.000    -0.008    -0.007\n\n\n\n\n\nnp.corrcoef(auto[\"weight\"], auto[\"mpg\"])\n\narray([[ 1.        , -0.83224421],\n       [-0.83224421,  1.        ]])\n\n\n\nFurther Reading:"
  },
  {
    "objectID": "IntroCoding_Lecture8.html",
    "href": "IntroCoding_Lecture8.html",
    "title": "9  String Manipulations, RegEx",
    "section": "",
    "text": "(Lecture 8)\nIn this lecture we will continue our journey of String Manipulation after reviewing list comprehensions"
  },
  {
    "objectID": "IntroCoding_Lecture8.html#list-comprehensions",
    "href": "IntroCoding_Lecture8.html#list-comprehensions",
    "title": "9  String Manipulations, RegEx",
    "section": "List Comprehensions",
    "text": "List Comprehensions\nList comprehensions are a convenient and widely used Python language feature. They allow you to concisely form a new list by filtering the elements of a collection, transforming the elements passing the filter into one concise expression. They take the basic form:\n[expr for value in collection if condition]\nThis is equivalent to the following for loop:\nresult = []\nfor value in collection:\n    if condition:\n        result.append(expr)\nThe filter condition can be omitted, leaving only the expression. For example, given a list of strings, we could filter out strings with length 2 or less and convert them to uppercase like this:\n\nstrings = [\"eye\", \"lived devil\", \"wow\", \"deed\", \"noon\", \"kayak\"]\n\nresults = []\n#convert those strings to upper case that are longer than 3 characters\nfor x in strings:\n  if len(x) > 3:\n    results.append(x.upper())\n\nresults\n\n['LIVED DEVIL', 'DEED', 'NOON', 'KAYAK']\n\n\n\n[x.upper() for x in strings if len(x) > 3]\n\n['LIVED DEVIL', 'DEED', 'NOON', 'KAYAK']\n\n\n\n[x.upper() for x in strings if len(x) > 3]\n\n\nDictionary Comprehension\nA dictionary comprehension looks like this:\ndict_comp = {key-expr: value-expr for value in collection\n             if condition}\nAs a simple dictionary comprehension example, we could create a lookup map of these strings for their locations in the list:\n\nresults = {}\nfor i, x in enumerate(strings):\n  results[x] = i\n\nresults\n\n{'eye': 0, 'lived devil': 1, 'wow': 2, 'deed': 3, 'noon': 4, 'kayak': 5}\n\n\n\nresults = {x:i for i, x in enumerate(strings) if len(x) > 3}\nresults\n\n{'lived devil': 1, 'deed': 3, 'noon': 4, 'kayak': 5}\n\n\nLike list comprehensions, set and dictionary comprehensions are mostly conveniences, but they similarly can make code both easier to write and read. Consider the list of strings from before. Suppose we wanted a set containing just the lengths of the strings contained in the collection; we could easily compute this using a set comprehension:\n\nunique_lengths = {len(x) for x in strings}\nunique_lengths"
  },
  {
    "objectID": "IntroCoding_Lecture8.html#string-operations",
    "href": "IntroCoding_Lecture8.html#string-operations",
    "title": "9  String Manipulations, RegEx",
    "section": "String Operations",
    "text": "String Operations\nBuilt-in methods\n\nmy_string = \"A man, a plan, a canal: Panama\"\nmy_string.lower()#this is not inplace\n\nTypeError: ignored\n\n\n\nmy_string\n\n'A man, a plan, a canal: Panama'\n\n\n\nmy_string.count(\"a\")#it is case sensitive\n\n9\n\n\n\nSplitting\n\nIndWords = my_string.split(sep = \" \")#both the colon and the commas are still present\nprint(IndWords)\n\n['A', 'man,', 'a', 'plan,', 'a', 'canal:', 'Panama']\n\n\n\nprint(my_string.split(sep=\",\"))\nprint(my_string.split(maxsplit=2))\n#Breaking at line boundaries\nprint(my_string.splitlines())\n\n['A man', ' a plan', ' a canal: Panama']\n['A', 'man,', 'a plan, a canal: Panama']\n['A man, a plan, a canal: Panama']\n\n\n\nmy_string = \"A man, a plan, a canal:\nPanama\"\n#Breaking at line boundaries\nprint(my_string.splitlines())\n\n\nmy_string = \"A man, a plan, a canal\\n Panama\"\nprint(my_string)\nprint(my_string.splitlines())\n\nA man, a plan, a canal\n Panama\n['A man, a plan, a canal', ' Panama']\n\n\n\n\nJoining\nConcatenate strings from iterables\n\nprint(\" \".join(IndWords))\n\nA man, a plan, a canal: Panama\n\n\n\n\nSlicing\n\nprint(my_string[0:5])#the same for numpy arrays or lists !\n\nA man\n\n\n\nprint(my_string[10:20:2])\n\nln  a\n\n\n\n\nPalindromes\nWhich words are palindromes ?\n\n\"eye kayak\"[::-1]\n\"Berlin\"[::-1]\n\n'nilreB'\n\n\n\n\"edit tide\"[::-1]\n\n'edit tide'\n\n\n\nprint(my_string[::-1])"
  },
  {
    "objectID": "IntroCoding_Lecture8.html#find-and-replace",
    "href": "IntroCoding_Lecture8.html#find-and-replace",
    "title": "9  String Manipulations, RegEx",
    "section": "Find and Replace",
    "text": "Find and Replace\n\nmy_string.find(\"Panama\")#success\n\n24\n\n\n\n my_string.find(\"Berlin\")#not found, failure\n\n-1\n\n\n\nmy_string.index(\"Panama\")\n\n24\n\n\n\nmy_string.replace(\"Panama\", \"Suez\")\n\n'A man, a plan, a canal\\n Suez'\n\n\n\nmy_string.replace(\"Berlin\", \"Suez\")#failure mode"
  },
  {
    "objectID": "IntroCoding_Lecture8.html#regular-expressions",
    "href": "IntroCoding_Lecture8.html#regular-expressions",
    "title": "9  String Manipulations, RegEx",
    "section": "Regular Expressions",
    "text": "Regular Expressions\n\nThe re module offers a set of functions that allows us to search a string for a match:\n\n\n\n\n\nFunction\n\n\nDescription\n\n\n\n\nfindall\n\n\nReturns a list containing all matches\n\n\n\n\nsearch\n\n\nReturns a Match object if there is a match anywhere in the string\n\n\n\n\nsplit\n\n\nReturns a list where the string has been split at each match\n\n\n\n\nsub\n\n\nReplaces one or many matches with a string\n\n\n\n\n\nMetacharacters are characters with a special meaning:\n\n\n\n\n\nCharacter\n\n\nDescription\n\n\nExample\n\n\nTry it\n\n\n\n\n[]\n\n\nA set of characters\n\n\n\"[a-m]\"\n\n\nTry it »\n\n\n\n\n</td>\n\nSignals a special sequence (can also be used to escape special characters)\n\n\n\"\"\n\n\nTry it »\n\n\n\n\n.\n\n\nAny character (except newline character)\n\n\n\"he..o\"\n\n\nTry it »\n\n\n\n\n^\n\n\nStarts with\n\n\n\"^hello\"\n\n\nTry it »\n\n\n\n\n*\n\n\nZero or more occurrences\n\n\n\"he.*o\"\n\n\nTry it »\n\n\n\n\n+\n\n\nOne or more occurrences\n\n\n\"he.+o\"\n\n\nTry it »\n\n\n\n\n?\n\n\nZero or one occurrences\n\n\n\"he.?o\"\n\n\nTry it »\n\n\n\n\n{}\n\n\nExactly the specified number of occurrences\n\n\n\"he.{2}o\"\n\n\nTry it »\n\n\n\n\n|\n\n\nEither or\n\n\n\"falls|stays\"\n\n\nTry it »\n\n\n\n\n()\n\n\nCapture and group\n\n\n \n\n\n \n\n\n\n\n\n#Find digits via \\d\nstring=\"The winners are: User2-4, UserN, User1, UserMarkus\"\nre.findall(r\"User\\d\", string)\n\n['User2', 'User1']\n\n\n\n#exclude digits via \\D\nre.findall(r\"User\\D\", string)\n\n['UserN']\n\n\n\n#find words via \\w\nre.findall(r\"User\\w\", string)\n\n['User2', 'UserN', 'User1', 'UserM']\n\n\n\n#white spaces \\s\nstring=\"Is it New York or  New-York?\"\nre.findall(r\"New\\sYork\", string)\n\n['New York']\n\n\n\n#not a white spaces \\S\nstring=\"Is it New York or  New-York?\"\nre.findall(r\"New\\SYork\", string)\n\n['New-York']\n\n\n\nRepetitions\n\nstring = \"my password is password1234\"\n#re.search(r\"\\w{8}\\d{4}\", string)\nre.findall(r\"\\w{8}\\d{4}\", string)\n\n['password1234']\n\n\n\n\nQuantifiers\nHow many times to match a pattern immediately to its left\n\n+ once or more\n* zero times or more\n? zero times or once\n{n,m} n times at least, m times at most\n\n\ntext = \"Possible exam dates: 6-25 or 7-5 or 2023-12-24\"\nre.findall(r\"\\d+-\\d+\", text)\n\n['6-25', '7-5', '2023-12']\n\n\n\ntext = \"Possible exam dates: 6-25 or 7-5 or 2023-12-24\"\nre.findall(r\"\\d+-\\d+-*\\d*\", text)\n\n['6-25', '7-5', '2023-12-24']\n\n\n\ntext = \"Possible exam dates: 6-25 or 7-5 or 2023-12-24\"\nre.findall(r\"\\d+-\\d+-?\\d?\", text)\n\n['6-25', '7-5', '2023-12-2']\n\n\n“Escaping” the special meaning of +\n\nphone_number = \"Mobile: +49 1578-1378941 or (49)1578-1378941\"\nre.findall(r\"\\+\\d{2}\\s*\\d{4}-\\d{7}\", phone_number)\n\n['+49 1578-1378941']\n\n\n“Escaping” the special meaning of ()\n\nre.findall(r\"\\(\\d{2}\\)\\s*\\d{4}-\\d{7}\", phone_number)\n\n['(49)1578-1378941']\n\n\nThe or operator |\n\nre.findall(r\"\\+\\d{2}\\s*\\d{4}-\\d{7}|\\(\\d{2}\\)\\s*\\d{4}-\\d{7}\", phone_number)\n\n['+49 1578-1378941', '(49)1578-1378941']\n\n\n\nphone_number = \"At HWR: 030-30877-1443 Mobile: 01578-1378941 or \"\nre.findall(r\"\\d{2,3}-\\d{4,5}-\\d{4}|\\d{5}-\\d{7}\", phone_number)\n\n['030-30877-1443', '01578-6798941']\n\n\n\n\nSpecial Characters\n\n. Match any character (except newlines)\n^ Start of the String\n$ End of the String\n\\ Escape special characters\n| OR operator\n[] group of characters\n\n\nmy_links = \"check out my blogs: https://markusloecher.github.io codeandstats.github.io\"\nre.findall(r\"https://.+github.io\", my_links)\n\n['https://markusloecher.github.io codeandstats.github.io']\n\n\n\nprint(re.findall(r\"^out\", my_links))\nre.findall(r\"^check\", my_links)\n\n[]\n\n\n['check']\n\n\n\nre.findall(r\"\\w+\\.github.io$\", my_links)\n\n['codeandstats.github.io']\n\n\n\nmy_links = \"check out my blogs: https://markusloecher.github.io codeandstats.github.io\"\nre.findall(r\"[a-z.]github.io\", my_links)\n\nNameError: ignored\n\n\n\nFurther Reading:"
  },
  {
    "objectID": "IntroCoding_Lecture9.html",
    "href": "IntroCoding_Lecture9.html",
    "title": "10  Subplots and Pivoting",
    "section": "",
    "text": "(Lecture 9)\nIn this lecture we will continue our journey of pandas after reviewing a few more details of matplotlib"
  },
  {
    "objectID": "IntroCoding_Lecture9.html#grid-of-subplots",
    "href": "IntroCoding_Lecture9.html#grid-of-subplots",
    "title": "10  Subplots and Pivoting",
    "section": "Grid of subplots",
    "text": "Grid of subplots\nA Figure object is the outermost container for a matplotlib graphic, which can contain multiple Axes objects. One source of confusion is the name: an Axes actually translates into what we think of as an individual plot or graph (rather than the plural of “axis,” as we might expect).\nYou can think of the Figure object as a box-like container holding one or more Axes (actual plots). Below the Axes in the hierarchy are smaller objects such as tick marks, individual lines, legends, and text boxes. Almost every “element” of a chart is its own manipulable Python object, all the way down to the ticks and labels:\n\n\n\nhttps://realpython.com/python-matplotlib-guide\n\n\n\nVia add_subplot()\n\n#create a grid of two rows and one column\nfig = plt.figure(figsize=(5, 3))\nax1 = fig.add_subplot(2, 1, 1)\nax2 = fig.add_subplot(2, 1, 2)\n\nRanNums = np.random.standard_normal(400)\nax1.hist(RanNums, bins=20, color=\"blue\", alpha=0.3);\nax1.set_title(\"Normal Distribution\");\n\nRanWalk = RanNums.cumsum()\nax2.plot(RanWalk, color=\"black\", linestyle=\"dashed\");\nax2.set_title(\"Random Walks\");\nfig.tight_layout()\n\n\n\n\n\n\nVia subplots()\nTo make creating a grid of subplots more convenient, matplotlib includes a plt.subplots method that creates a new figure and returns a NumPy array containing the created subplot objects:\n\n\nMath Notations in Notebook\nIf you wanted to show a sum using fancy math notations you would deploy Latex\n\\(\\alpha = \\sum_{i=1}^N{\\sqrt{x_i}}\\)\n\nx = np.random.randint(low=1, high=11, size=50)\ny = x + np.random.randint(1, 5, size=x.size)\ndata = np.column_stack((x, y))\n\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2,\n                               figsize=(8, 4))\n\nax1.scatter(x=x, y=y, marker='o', c='r', edgecolor='b')\nax1.set_title('Scatter: $x$ versus $y$')\nax1.set_xlabel('$x$')\nax1.set_ylabel('$y$')\n\nax2.hist(data, bins=np.arange(data.min(), data.max()),\n         label=('x', 'y'))\nax2.legend(loc=(0.65, 0.8))\nax2.set_title('Frequencies of $x$ and $y$')\nax2.yaxis.tick_right()\n\n\n\n\n\n\n\nTable 9.1: matplotlib.pyplot.subplots options\n\n\n\n\nArgument\n\n\nDescription\n\n\n\n\n\n\nnrows\n\n\nNumber of rows of subplots\n\n\n\n\nncols\n\n\nNumber of columns of subplots\n\n\n\n\nsharex\n\n\nAll subplots should use the same x-axis ticks (adjusting the xlim will affect all subplots)\n\n\n\n\nsharey\n\n\nAll subplots should use the same y-axis ticks (adjusting the ylim will affect all subplots)\n\n\n\n\nsubplot_kw\n\n\nDictionary of keywords passed to add_subplot call used to create each subplot\n\n\n\n\n**fig_kw\n\n\nAdditional keywords to subplots are used when creating the figure, such as plt.subplots(2, 2, figsize=(8, 6))\n\n\n\n\n\n\n\nAnnotations\n\nfrom datetime import datetime\nurl = \"https://raw.githubusercontent.com/wesm/pydata-book/3rd-edition/examples/spx.csv\"\nstock_data = pd.read_csv(url, index_col=0, parse_dates=True)\nspx = stock_data[\"SPX\"]\n\n\nstock_data.head()\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      SPX\n    \n    \n      Date\n      \n    \n  \n  \n    \n      1990-02-01\n      328.79\n    \n    \n      1990-02-02\n      330.92\n    \n    \n      1990-02-05\n      331.85\n    \n    \n      1990-02-06\n      329.66\n    \n    \n      1990-02-07\n      333.75\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nspx[0]\n\nspx[\"2007-10-11\"]\n\nspx.asof(datetime(2007, 10, 11))\n\n1554.41\n\n\n\ncrisis_data = [\n    (datetime(2007, 10, 11), \"Peak of bull market\"),\n    (datetime(2008, 3, 12), \"Bear Stearns Fails\"),\n    (datetime(2008, 9, 15), \"Lehman Bankruptcy\")\n]\n\n#crisis_data[0][0]\nspx.asof(crisis_data[0][0])\n\n1554.41\n\n\n\nfig, ax = plt.subplots(figsize=(7, 3.5))\n\nspx.plot(ax=ax, color=\"black\");\n\nfor date, label in crisis_data:\n    ax.annotate(label, xy=(date, spx.asof(date) + 75),\n                xytext=(date, spx.asof(date) + 225),\n                arrowprops=dict(facecolor=\"black\", headwidth=4, width=2,\n                                headlength=4),\n                horizontalalignment=\"left\", verticalalignment=\"top\")\n\n# Zoom in on 2007-2010\nax.set_xlim([\"1/1/2007\", \"1/1/2011\"])\nax.set_ylim([600, 1800])\n\nax.set_title(\"Important dates in the 2008–2009 financial crisis\");\n\n\n\n\n\n\nLegends\n\nfig, ax = plt.subplots(figsize=(7, 3.5))\n\nax.plot(np.random.randn(1000).cumsum(), color=\"black\", label=\"one\");\nax.plot(np.random.randn(1000).cumsum(), color=\"black\", linestyle=\"dashed\",label=\"two\");\nax.plot(np.random.randn(1000).cumsum(), color=\"black\", linestyle=\"dotted\",label=\"three\");\n#I would expect a legend to be a lot of work\n# I would have to specify which lines has which legend\nax.legend();"
  },
  {
    "objectID": "IntroCoding_Lecture9.html#pandas",
    "href": "IntroCoding_Lecture9.html#pandas",
    "title": "10  Subplots and Pivoting",
    "section": "Pandas",
    "text": "Pandas\n\nAssign\nWe have already created new columns on the fly by the [] method. There is also a built-in method assign()\n\ndf = pd.DataFrame({'temp_c': [17.0, 25.0]},index=['Portland', 'Berkeley'])\ndf\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      temp_c\n    \n  \n  \n    \n      Portland\n      17.0\n    \n    \n      Berkeley\n      25.0\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\ncreate a new column which measures temperature in Fahrenheit \\(9/5 \\cdot C + 32\\)\n\n#method1\ndf[\"temp_f\"] = 9/5 * df[\"temp_c\"] + 32\ndf\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      temp_c\n      temp_f\n    \n  \n  \n    \n      Portland\n      17.0\n      62.6\n    \n    \n      Berkeley\n      25.0\n      77.0\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ndf.assign(temp_f=df['temp_c'] * 9 / 5 + 32)\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      temp_c\n      temp_f\n    \n  \n  \n    \n      Portland\n      17.0\n      62.6\n    \n    \n      Berkeley\n      25.0\n      77.0\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ndf.assign(temp_f = df['temp_c'] * 9 / 5 + 32,\n          temp_k = df['temp_c'] + 273.15)\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      temp_c\n      temp_f\n      temp_k\n    \n  \n  \n    \n      Portland\n      17.0\n      62.6\n      290.15\n    \n    \n      Berkeley\n      25.0\n      77.0\n      298.15\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n#What does lambda mean ?\ndef ConvertCtoF(x):\n  return x['temp_c'] * 9 / 5 + 32\n\n#ConvertCtoF(df)\ndf.assign(temp_f = ConvertCtoF(df))\n\n#this is a lot of overhead to efine a function that does basically a one-liner\nlambda x: x['temp_c'] * 9 / 5 + 32\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      temp_c\n      temp_f\n    \n  \n  \n    \n      Portland\n      17.0\n      62.6\n    \n    \n      Berkeley\n      25.0\n      77.0\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\nYou can create multiple columns within the same assign where one of the columns depends on another one defined within the same assign:\n\ndf.assign(temp_f=lambda x: x['temp_c'] * 9 / 5 + 32,\n    temp_k=lambda x: (x['temp_f'] + 459.67) * 5 / 9)\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      temp_c\n      temp_f\n      temp_k\n    \n  \n  \n    \n      Portland\n      17.0\n      62.6\n      290.15\n    \n    \n      Berkeley\n      25.0\n      77.0\n      298.15\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\n\nPivoting\nIn Pandas, the pivot table function takes simple data frame as input, and performs grouped operations that provides a multidimensional summary of the data.\nYou can also think of it as a long to wide translation.\n\nstocks_long = pd.read_csv('https://gist.githubusercontent.com/alexdebrie/b3f40efc3dd7664df5a20f5eee85e854/raw/ee3e6feccba2464cbbc2e185fb17961c53d2a7f5/stocks.csv')\nstocks_long.head()\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      date\n      symbol\n      open\n      high\n      low\n      close\n      volume\n    \n  \n  \n    \n      0\n      2019-03-01\n      AMZN\n      1655.13\n      1674.26\n      1651.00\n      1671.73\n      4974877\n    \n    \n      1\n      2019-03-04\n      AMZN\n      1685.00\n      1709.43\n      1674.36\n      1696.17\n      6167358\n    \n    \n      2\n      2019-03-05\n      AMZN\n      1702.95\n      1707.80\n      1689.01\n      1692.43\n      3681522\n    \n    \n      3\n      2019-03-06\n      AMZN\n      1695.97\n      1697.75\n      1668.28\n      1668.95\n      3996001\n    \n    \n      4\n      2019-03-07\n      AMZN\n      1667.37\n      1669.75\n      1620.51\n      1625.95\n      4957017\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nstocks_long[\"date\"].unique()\n#stocks_long[\"symbol\"].unique()\nstocks_long.shape\n\n(15, 7)\n\n\nThe data has a number of columns and that the rows are organized by trading date and stock symbol.\nThat organization may be helpful for some analysis, but it can be hard to glean information about trading volume across dates and stock symbols. Let’s reshape our data to look closer at volume.\n\nstocks_wide = stocks_long.pivot(index='symbol', columns='date', values='volume')\nprint(stocks_wide.shape)\nstocks_wide\n\n(3, 5)\n\n\n\n\n  \n    \n      \n\n\n  \n    \n      date\n      2019-03-01\n      2019-03-04\n      2019-03-05\n      2019-03-06\n      2019-03-07\n    \n    \n      symbol\n      \n      \n      \n      \n      \n    \n  \n  \n    \n      AAPL\n      25886167\n      27436203\n      19737419\n      20810384\n      24796374\n    \n    \n      AMZN\n      4974877\n      6167358\n      3681522\n      3996001\n      4957017\n    \n    \n      GOOG\n      1450316\n      1446047\n      1443174\n      1099289\n      1166559\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\nHow to use the Pandas pivot method\nTo use the pivot method in Pandas, you need to specify three parameters:\n\nIndex: Which column should be used to identify and order your rows vertically\nColumns: Which column should be used to create the new columns in our reshaped DataFrame. Each unique value in the column stated here will create a column in our new DataFrame.\nValues: Which column(s) should be used to fill the values in the cells of our DataFrame.\n\nIn the example below, I use pivot to examine the closing trading price for each stock symbol over our trading window.\n\nstocks_long.pivot(index='date', columns='symbol', values=['close', \"volume\"])\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      close\n      volume\n    \n    \n      symbol\n      AAPL\n      AMZN\n      GOOG\n      AAPL\n      AMZN\n      GOOG\n    \n    \n      date\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2019-03-01\n      174.97\n      1671.73\n      1140.99\n      25886167.0\n      4974877.0\n      1450316.0\n    \n    \n      2019-03-04\n      175.85\n      1696.17\n      1147.80\n      27436203.0\n      6167358.0\n      1446047.0\n    \n    \n      2019-03-05\n      175.53\n      1692.43\n      1162.03\n      19737419.0\n      3681522.0\n      1443174.0\n    \n    \n      2019-03-06\n      174.52\n      1668.95\n      1157.86\n      20810384.0\n      3996001.0\n      1099289.0\n    \n    \n      2019-03-07\n      172.50\n      1625.95\n      1143.30\n      24796374.0\n      4957017.0\n      1166559.0"
  },
  {
    "objectID": "IntroCoding_Lecture9.html#smoking-data",
    "href": "IntroCoding_Lecture9.html#smoking-data",
    "title": "10  Subplots and Pivoting",
    "section": "Smoking Data",
    "text": "Smoking Data\n3 columns: “outcome” measures whether the person is still alive after 10 years.\nWe want to glean the effect of smoking on survival probability.\n\ndf = pd.read_csv(\"https://calmcode.io/datasets/smoking.csv\")\ndf.head()\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      outcome\n      smoker\n      age\n    \n  \n  \n    \n      0\n      Alive\n      Yes\n      23\n    \n    \n      1\n      Alive\n      Yes\n      18\n    \n    \n      2\n      Dead\n      Yes\n      71\n    \n    \n      3\n      Alive\n      No\n      67\n    \n    \n      4\n      Alive\n      No\n      64\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ndf.shape\n\n(1314, 3)\n\n\n\ndf.mean()\n\nFutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  df.mean()\n\n\nage    46.920091\ndtype: float64\n\n\n\ndf = df.assign(alive = (df['outcome'] == 'Alive').astype(int),\n               smokes = (df['smoker'] == 'Yes').astype(int))\ndf.head()\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      outcome\n      smoker\n      age\n      alive\n      smokes\n    \n  \n  \n    \n      0\n      Alive\n      Yes\n      23\n      1\n      1\n    \n    \n      1\n      Alive\n      Yes\n      18\n      1\n      1\n    \n    \n      2\n      Dead\n      Yes\n      71\n      0\n      1\n    \n    \n      3\n      Alive\n      No\n      67\n      1\n      0\n    \n    \n      4\n      Alive\n      No\n      64\n      1\n      0\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\ndf.mean()\n#71.9% is  is the overall survival rate for all people\n#How would you separately compute this for smokers and non smokers ?\n#groupby is your friend !!\n\nFutureWarning: The default value of numeric_only in DataFrame.mean is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n  df.mean()\n\n\nage       46.920091\nalive      0.719178\nsmokes     0.442922\ndtype: float64\n\n\nSmoking is good for your health\n\ndf.groupby(['smoker']).alive.mean()\n\nsmoker\nNo     0.685792\nYes    0.761168\nName: alive, dtype: float64\n\n\n\ndf.groupby(['smoker']).agg(prob=('alive', np.mean))\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      prob\n    \n    \n      smoker\n      \n    \n  \n  \n    \n      No\n      0.685792\n    \n    \n      Yes\n      0.761168\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\nAge adjustment\n\ndf = df.assign(age10 =np.round(df['age'] / 10) * 10)\n\n\n(df.groupby(['age10'])\n  .agg(p_alive=('alive', np.mean)\n   ,p_smokes=('smokes', np.mean)))\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      p_alive\n      p_smokes\n    \n    \n      age10\n      \n      \n    \n  \n  \n    \n      20.0\n      0.980645\n      0.445161\n    \n    \n      30.0\n      0.972332\n      0.438735\n    \n    \n      40.0\n      0.900000\n      0.495833\n    \n    \n      50.0\n      0.821622\n      0.632432\n    \n    \n      60.0\n      0.587302\n      0.464286\n    \n    \n      70.0\n      0.203947\n      0.236842\n    \n    \n      80.0\n      0.000000\n      0.168831\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nfrom datetime import datetime\n\ndatetime(2018, 6, 24)\n\ndatetime.datetime(2018, 6, 24, 0, 0)\n\n\nGroup by age and smoking status and plot the survival rates separately for the two groups\n\nFurther Reading:"
  }
]